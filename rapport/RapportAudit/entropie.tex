\chapter{Entropie}
\section{Définitions et contexte}

\subsection{Introduction}
Cette partie explicite les notions d'entropie nécessaires pour la définition d'aléatoire de certains programmes, mais décrit aussi les sources qui de génération de bits aléatoires et les tests liés. \\



Trois axes principaux sont nécessaires à la mise en place d'un générateur cryptographique aléatoire de bits  : 
\begin{itemize}
\item Une source de bits aléatoires (source d'entropie)
\item Un algorithme pour accumuler ces bits reçus et les faire suivre vers l'application en nécessitant.
\item Une méthode appropriée pour combiner ces deux premiers composants\\
\end{itemize}


\subsection{Estimation de l'entropie générée par la source}
Il est tout d'abord important de vérifier que la source d'entropie choisie produit suffisamment d'entropie, à un taux égalant voire dépassant une borne fixée. Pour ce faire, il faut définir avec précision la quantité d'entropie générée par la source. Il est de plus important de considérer les différents comportements des composants de la source, afin d'éliminer les interactions qu'ils peut y avoir entre les composants. En effet, ceci peut provoquer une redondance dans la génération d'entropie si cela n'est pas considéré. Étant donné une source biaisée, l'entropie générée sera conditionnée et donc plus facilement prévisible/estimable.

La source d'entropie doit donc être minutieusement choisie, sans qu'aucune interaction et conditionnement ne soit possible.

\subsection{Concept d'entropie}
\paragraph{Définition.\\}
Soit $X$ est une V.A. discrète. On définit l'\textbf{entropie} de $X$ comme suit : 
$$H(X) = - \sum_x P(X=x)*log(P(X=x))	 $$ 
Le logarithme est dans notre cas de base 2. L'entropie se mesure en shannons ou en bits.\\

\paragraph{Définition.\\}
On définit le \textbf{désordre} (ou incertitude) étant liée à cette expérience aléatoire. Si l'on considère l'ensemble fini des issues possibles d'une expérience $\lbrace v_1,...,v_n \rbrace$, l'entropie de l'expérience vaudra :
$$H(\epsilon) = - \sum_x P(\lbrace a_i \rbrace)*log(P(\lbrace a_i \rbrace))	 $$ 

\paragraph{Propriété.\\} 
On constate que l'entropie est maximale lorsque X est équi-répartie. En effet, si l'on considère n éléments de X étant équi-répartie, on retrouve notre entropie de $H(X) = log(n)$. \\


Ainsi, on comprend qu'une variable aléatoire apporte en moyenne un maximum d'entropie lorsqu'elle peut prendre chaque valeur avec une équiprobabilité. D'un point de vue moins théorique, on considère que plus l'entropie sera grande, plus il sera difficile de prévoir la valeur que l'on observe.

\paragraph{Min-entropy.\\}
La recommandation du NIST propose le calcul de \textit{Min-entropy} pour mesurer au pire des cas l'entropie d'une observation. \\

Soit $x_i$ un bruit de la source d'entropie. Soit $p(x_i)$ la probabilité d'obtenir $x_i$. On définit l'entropie au pire des cas telle que : 
$$\text{Min-entropy}=-log_2(max(p(x_i))$$
La probabilité d'observer $x_i$ sera donc au minimum  $\frac{1}{2^\text{Min-entropy}}$.

\subsection{Source d'entropie}
\paragraph{Approche théorique.\\}
La source d'entropie est composée de 3 éléments principaux : 
\begin{itemize}
\item le \textbf{bruit source}, qui est la voûte de la sécurité du système. Ce bruit doit être non déterministe, il renvoie de façon aléatoire des bits grâce à des processus non déterministes. Le bruit ne vient pas nécessairement directement d'éléments binaires. Si ce bruit est externe, il est alors converti en données binaires. La taille des données binaires générées est fixée, de telle sorte que la sortie du bruit source soit déterminé dans un espace fixe.
\item le \textbf{composant de conditionnement}, qui permet d'augmenter ou diminuer le taux d'entropie reçu. L'algorithme de conditionnement doit être un algorithme cryptographique approuvé.
\item une \textbf{batterie de tests}, partie également intégrante du système. Des tests sont réalisés pour déterminer l'état de santé du générateur aléatoire, permettant de s'assurer que la source d'entropie fonctionne comme attendu. On considère 3 catégories de tests : 
	\begin{itemize}
	\item Les tests au démarrage sur tous les composants de la source
	\item Les tests lancés de façon continue sur le bruit généré par la source
	\item Les tests sur demande (qui peuvent prendre du temps)
	\end{itemize}
	L'objectif principal de ces tests est d'être capable d'identifier rapidement des échecs de génération d'entropie, ceci avec une forte probabilité. Il est donc important de déterminer une bonne stratégie de détermination d'échec pour chacun de ces tests.\\
\end{itemize}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node (source) {\textbf{Source d'entropie}};
\node (bruit) [below of=source,yshift=1cm,xshift=0.5cm] {\textbf{Bruit}};
\node (donnees) [io,below of=bruit,yshift=1cm,xshift=0.5cm,pattern=dots,pattern color=orange] {Données};
\node (digit) [process, right of=donnees, xshift=4cm] {Digitalisation};
\node (cond) [process, below of=digit,text width=3cm,yshift=-0.5cm] {Conditionnement (optionnel)};
\node (bat) [process, right of=cond, xshift=4cm] {Batterie de tests}; 
\node (dec) [decision, below of=cond,yshift=-0.5cm] {Sortie}; 
\node (appli) [process, below of=dec, yshift=-1cm] {Application};

\begin{pgfonlayer}{background}
\node[punkt, fit=(donnees)(digit)(cond)(bat)(dec)(bruit)(source), fill=yellow!5] (groupclient) {};
\end{pgfonlayer}

\begin{pgfonlayer}{background}
\node[punkt, fit=(donnees)(digit)(bruit), fill=yellow!20] (groupclient) {};
\end{pgfonlayer}

\draw [arrow] (donnees) -- (digit);
\draw [arrow] (digit) -- node[anchor=east] {out1}(cond);
\draw [arrow] (cond) --  node[anchor=east] {out2} (dec);
\draw [arrow] (digit) -| node[anchor=south] {out1} (bat);
\draw [arrow] (cond) -- node[anchor=south] {out2} (bat);
\draw [arrow] (bat) |- node[anchor=north] {true/false} (dec);
\draw [arrow] (dec) -- node[anchor=east] {output/error}  (appli);
\end{tikzpicture}
\end{center}
\caption{Composants d'une source d'entropie. \texttt{out1} est une chaîne binaire de taille quelconque et \texttt{out2} est une chaîne binaire conditionnée de taille fixe. }
\end{figure}

\paragraph{Modèle conceptuel.\\}
Suivant ces sections précédentes, on peut déterminer 3 interfaces conceptuelle :
\begin{itemize}
\item \texttt{getEntropy} qui retourne 
	\begin{itemize}
	\item \texttt{entropy\_bitstring}, une chaîne de bits de l'entropie demandée
	\item \texttt{assessed\_entropy}, entier indiquant le nombre de bits d'entropie de \texttt{entropy\_bitstring}
	\item \texttt{status}, booléen renvoyant \texttt{true} si la requête est satisfaite, \texttt{false} sinon.\\
	\end{itemize}
\item \texttt{getNoise}	 qui prend en entrée : 
	\begin{itemize}
	\item \texttt{number\_of\_sample\_requested}, entier indiquant le nombre d'éléments demandés en retour à la source de bruit
	\end{itemize}
et en sortie : 
	\begin{itemize}
	\item \texttt{noise\_source\_data}, la séquences d'éléments demandée, ayant la taille \texttt{number\_of\_sample\_requested}.
	\item \texttt{status}, booléen renvoyant \texttt{true} si la requête est satisfaite, \texttt{false} sinon.\\
	\end{itemize}
\item \texttt{HealthTest}, élément test de la batterie de tests, qui prend en entrée :
	\begin{itemize}
	\item \texttt{type\_of\_test\_requested}, chaine de bits déterminant le type de tests que l'on souhaite effectuer (peut différer suivant le type de source)
	\end{itemize}
et en sortie : 
	\begin{itemize}
	\item \texttt{pass-fail\_flag}, booléen qui renvoie \texttt{true} si la source d'entropie a réussi le test, \texttt{faux} sinon.
	\end{itemize}	
\end{itemize}


\subsection{Standards}
	\subsubsection{RFC 4086}

			Nos machines utilise ce qu'on appel des PRNG (Pseudo Random Number
			Generator), ce sont des algorithmes qui génèrent une 
			séquence de nombre s'apparentant à de l'aléatoire.
			En réalité rien est aléatoire car tout est déterminé par
			des valeurs initiales (État du PRNG) et des contextes 
			d'utilisation.\\
			
			Un bon PRNG se doit d'avoir une très forte entropie (proche de un),
			afin d'éviter de délivrer de l'information.
		
			Comme l'entropie est fourni majoritairement (si ce n'est totalement)
			par l'OS, il est donc nécessaire de détailler les PRNG les plus
			utilisés (surtout par les systèmes Linux et BSD - qui sont 
			ceux qui génèrent le plus de certificats SSL).\\
		
			Nous nous basons sur la RFC 4086 \cite{rfc4086}: 
			\textit{Randomness requirements for security}
			pour le choix des PRNG selon les différents	systèmes, voir
			la section "Normes" pour plus d'informations.	
	
		\subsubsubsection{Sous Linux}
		
			Il existe plusieurs niveaux de récupération d'aléatoire sous linux  :\\
			\begin{itemize}
			\item Point primaire (\textit{Primary pool}) :\\
			512o (128 mots de 4o) + ajout d’entropie\\
			\item Point secondaire (\textit{Secondary pool}) :\\
			128o pour générer le fichier \texttt{/dev/random}. \\
			Un autre point secondaire existe : \texttt{/dev/urandom}\\
			\end{itemize}
			
			L'entropie est récupérée par exemple lorsqu'un événement apparaît 
			(telle qu'une interruption du disque dur), la date et l'heure de 
			l'événement est récupéré et XORée dans le \textit{pool}, puis est 
			"mélangée" avec une primitive polynomiale possédant un degré de 128. 
			Le \textit{pool} devient ensuite une boucle où de nouvelles données 
			sont XORées ("mélangées" encore par la primitive polynomiale) tout 
			le long du \textit{pool}.\\
			
			A chaque appel qui rajoute de l'entropie dans le \textit{pool}, 
			celui-ci calcule une estimation de la probabilité d'une réelle 
			entropie des données. 
			Le \textit{pool} contient alors l'accumulation des estimations 
			de l'entropie totale contenue dans le \textit{pool}.\\
						
			Les sources d'entropie sont les suivantes :
			\begin{itemize}
			\item Interruption Clavier - heure et code d'interruption 
			\item Interruption des complétions du disque - heure de 
			lecture ou écriture
			\item Mouvements de la souris - heure et position\\
			\end{itemize}
			
			Quand des octets aléatoires sont demandés, la \textit{pool} 
			est haché avec SHA-1 (20 octets). Si plus de 20 octets 
			est demandé, le haché est mélangé dans la \textit{pool} 
			pour la rehacher ensuite, etc. À chaque fois que l’on prend des 
			octets dans la \textit{pool}, l’entropie estimée est décrémentée. 
			Pour assurer un niveau minimum d'entropie au démarrage, 
			la \textit{pool} est écrite dans un fichier à l'extinction 
			de la machine.\\
			
			\texttt{/dev/urandom} fonctionne selon le même principe sauf 
			qu'il n'attend pas qu'il y ait assez d'entropie pour donner de 
			l'aléatoire. Il convient pour une génération de clefs de session. 
			Pour générer des clefs cryptographiques de longue durée, il 
			est recommandé d'utiliser \texttt{/dev/random} pour assurer 
			un niveau minimum d'entropie.\\
			
			\texttt{/dev/random} utilise une \textit{pool} d'entropie de 409
			bits (512 octets) génère de l'aléa et s'arrête lorsqu'il n'y a 
			plus assez d’entropie et attend que la \textit{pool} se remplisse 
			à nouveau.\\
			
			En conclusion, \texttt{/dev/random} doit être utilisé pour une haute 
			qualité d'entropie (i.e. haute sécurité de chiffrement, one-time
			pad).\\
			Tandis que \texttt{/dev/urandom} doit être utilisé pour des
			applications non sensibles à des attaques cryptographiques 
			(i.e. jeu en temps réel), car elle génère plus d'entropie que 
			\texttt{/dev/random} sur un temps donné, mais s'arrêtera même 
			si il n'a pas récolté suffisamment d'entropie.\\

			Par exemple, sur un serveur sans souris ni clavier, 
			définir l'entropie avec	\texttt{/dev/urandom} est très risqué. 
			On recommande donc l'utilisation de \texttt{/dev/random} lors de 
			l'audit OpenSSL sur les versions Linux.\\
	
			Si vous souhaitez connaître l'entropie disponible, la commande 
			est :
			\begin{center}
				\texttt{cat /proc/sys/kernel/random/entropy\_avail}
			\end{center}	
			
			Désormais, la taille de la pool est hardcodée dans le noyau Linux 
			(\texttt{/drivers/char/random.c:275})\\
			
			Linux offre également la possibilité de récupérer de l’aléa depuis 
			un RNG matériel avec la fonction \texttt{get\_random\_bytes\_arch}
			\cite{archlinuxRNG}\\
		
			Un patch est également disponible afin de générer de l'aléa avec un 
			débit de 100kB/s \cite{mueller2013rng}. 
			L'entropie est récupérée par le CPU timing jitter.\\
			
		\subsubsubsection{Sous Windows}
		
			Du coté de Microsoft, il est recommandé aux utilisateurs d'utiliser 
			\texttt{CryptGenRandom}, \cite{wikicryptgenrandom}
			qui est un appel système de génération d'un nombre pseudo-aléatoire. 
			La génération est réalisée par une librairie cryptographique
			 (\textit{Cryptographic service provider library}).
			Celle-ci gère un pointeur vers un \textit{buffer} en lui 
			fournissant de l'entropie afin de générer un nombre pseudo 
			aléatoire en retour avec en plus, le nombre	d'octets d'aléatoires
			désirés.
			
			\begin{verbatim}
			BOOL WINAPI CryptGenRandom(
			  _In_     HCRYPTPROV hProv,
			  _In_     DWORD dwLen,
			  _Inout_  BYTE *pbBuffer
			);
			\end{verbatim}
			
			Le service \textit{provider} sauvegarde une variable d'état d'un 
			sel pour chaque utilisateur. Lorsque \texttt{CryptGenRandom} est 
			appelé, celui-ci est combiné avec un nombre aléatoire généré par 
			la librairie en plus de différentes données systèmes mais aussi de 
			l'utilisateur telles que :\\
			\begin{itemize}
			\item l’ID du processus
			\item l'ID du thread
			\item l'horloge système
			\item l'heure système
			\item l'état de la mémoire
			\item l’espace de disque disponible du cluster
			\item le haché du block d'environnement mémoire de l’utilisateur\\
			\end{itemize} 
			
			Le tout est envoyé à la fonction de hachage SHA-1 et le nombre en 
			sortie est utilisé comme sel de clef RC4.  
			Cette clef est enfin utilisée pour produire des données 
			pseudo-aléatoires et mettre à jour la variable d'état du sel de 
			l'utilisateur. 
			
		\subsubsubsection{Sous OpenBSD et FreeBSD}
			
			Il faut faire attention au faux ami, le \texttt{/dev/random} 
			du FreeBSD n'est pas le même que celui de Linux.
			En fait, il est semblable au \texttt{/dev/urandom} de Linux, 
			et est donc tout autant proscrit lors de notre audit.\\
			
			Dans OpenBSD, on trouve des sources d'aléatoire supplémentaires 
			par rapport à Linux. On trouve notamment \texttt{/dev/arandom} qui 
			génère de l'aléatoire selon une version leakée de \texttt{RC4} :
			\texttt{ARC4} (Alleged RC4). Pour rappel, \texttt{RC4} était 
			un projet commercial de \texttt{RSA Security} et un hacker 
			anonyme a publié un code qui faisait la même chose, 
			code légitime identifié par \texttt{ARC4}. 
			De nos jours, il est fortement conseillé de ne plus utiliser
			\texttt{RC4} car le flux de données aléatoires n'est pas vraiment 
			aléatoire et il existe des attaques qui prédisent la sortie de 
			l'algorithme (Attaque de Fluhrer, Mantin et Shamir) 
			\nocite{Fluhrer01weaknessesin}.	
			
			Sur plusieurs de nos sources (plus anciennes), il est recommandé
			d'utiliser \texttt{/dev/arandom} pour sa rapidité 
			(71 Mb/s) et sa bonne source d'entropie. 
			Ce n'est plus vraiment le cas aujourd'hui.\\

	
		\subsubsubsection{Autres systèmes}
		
			Nous avons également d'autres RNG comme \texttt{/dev/srandom},
			\texttt{/dev/prandom} ou encore \texttt{/dev/wrandom}
			\cite{miros2013}\\
			
			\texttt{/dev/srandom} est simple et lent, il n'est pas recommandé de 
			l'utilisé.\\
		
			Certains systèmes ne disposant pas de \texttt{/dev/*random}, 
			il est alors possible d'utiliser l'EGD (Entropy Gathering Daemon) 
			\cite{egdsf.net}.\\
			
			Il faut pour cela utiliser les fonctions OpenSSL \texttt{RAND\_egd}, 
			\texttt{RAND\_egd\_bytes} et \texttt{RAND\_query\_egd\_bytes}. \\

			L'EGD est également utilisé par GPG, et peut être utilisé comme 
			seed.
			
	\subsubsection{FIPS 140}
	
		Le FIPS 140 (\textit{Ferderal Information Processing Standards} est un 
		standard du gouvernement américain spécifique aux modules cryptographiques 
		déployés par des éléments du gouvernement. Il inclue notamment des standards 
		de tests qui permettent de qualifier la qualité et/ou validation des 
		générateurs d'entropie ou générateurs pseudos aléatoires. 
		La dernière version en présence est le FIPS 140-2, qui décrit plusieurs 
		niveaux de tests.\\
		
		
		Les test du FIPS 140-1 permet de s'assurer que les sources d'entropies 
		produisent suffisamment de "bonnes" données, pourvu que les sources d'entropies 
		n'utilisent pas quelques opérations cryptographiques internes. Si elle en utilise, 
		la source d'entropie réussira les tests avec quasi- certitude, même si la source 
		d'entropie est faible. Pour la même raison,  ces jeux de tests ne sont pas bon 
		pour tester des des générateurs de nombres pseudo-aléatoires cryptographiques, 
		car ceux-ci passeront facilement les tests même si les générateurs d'entropie 
		sont faibles. Par exemple, si l'on hache une suite d'entiers (par pas de 1), 
		les tests seront tous validés bien qu'ils n'auront pas été tirés aléatoirement, 
		ceci en vertu de la fonction de hachage. Pourtant, la donnée est hautement
		prédictible.\\
		
		
		Les tests du FIPS 140-2 ne sont également pas très efficaces, excepté si un matériel 
		commence à produire un motif répété. Ils consistent à comparer différentes sorties 
		consécutives d'un générateur.  De telle sorte, si le "générateur aléatoire" consiste 
		à produire une simple incrémentation, les tests passeront sans problème.
		
		Il est donc conseillé d'utiliser les tests du FIPS 140-1 pour vérifier uniquement 
		si la source d'entropie produit de bonnes données, au démarrage et périodiquement 
		lorsque c'est possible. 
		
		
		Le FIPS 140-1 définit 4 tests statistiques à lancer sur 20000 bits consécutifs, 
		tests au démarrage ou à la demande : 
		\begin{enumerate}
		\item Le \textbf{test Monobit}, où le nombre de bits à 1 sont comptés. 
		Le test est considéré comme réussi si le nombre de bits à 1 est 
		raisonnablement proche de 10000.
		\item Le \textbf{test Poker}, pour lequel les données sont séparées en 
		une suite consécutive de 4bits pour déterminer combien de fois les 16 
		configurations de 4 bits apparaissent. Les carrés du résultats sont sommés 
		et permettent de définir si le test passe ou non. 
		\item Le \textbf{test runs}, que nous développerons dans les 
		recommandations du NIST.
		\item Le test \textbf{long runs}, qui effectue le test de runs sur 
		34 bits ou davantage.\\
		\end{enumerate}
		
		
		Le FIPS 140-2 définit enfin des tests continuels de sortie 
		(\textit{continuous output tests}). Les données de sorties sont découpés 
		en blocs de 16 octets (ou davantage). Le premier block est stocké et 
		comparé second. S'ils sont identiques, alors le test est échoué. On passe 
		à la paire suivante, le 2e bloc est comparé avec le 3e, etc.

\section{Une backdoor dans nos sytèmes cryptographiques?}

	\subsection{L'affaire Snowden et les documents top secrets de la NSA}
	
	Coup d'éclat en 2012, Edward Snowden, ancien-membre de la NSA et de
	la CIA,	dévoile l'existence des backdoors ainsi qu'un lot
	d'informations conséquent sur la forte affluence de la NSA
	sur le NIST et la RSA \cite{snowden2013reuters}.\\
	
	Il préleva ainsi plus de 1.700.000 documents de la NSA (d'après un 
	officier de la NSA - 15 décembre 2013), dont 31.000 
	ultra-confidentiels \cite{wikiSnowden}.\\
	
	Il délivra quelques documents à plusieurs journaux populaires
	tels que \textit{"The Guardian"} et \textit{"The New York Times"}.\\
	
	Parmis les documents top secrets rendus publiques, un en particulier
	nous intéresse \cite{topsecretNSA}, il concerne le contrôle de la NSA 
	sur les systèmes de chiffrement actuels, nom de code \texttt{BULLRUN},
	voici quelques points importants :\\
	\begin{itemize}
		\item Insert vulnerabilities into commercial encryption systems, IT 
		systems, networks, endpoint communications devices used by targets
		\item Influence policies, standards and specification for commercial 
		public key technologies\\
	\end{itemize}
	
	Bruce Schneier, un des plus grands cryptologues actuel,
	et fervent détracteur de la NSA, publie plusieurs articles concernant
	ce contrôle d'informations sur la question "La NSA a t-elle 
	réellement placé une backdoor au sein d'un nouveau système de 
	chiffrement?" \cite{schneier2007NSA} \\

	Il évoque également le projet \texttt{BULLRUN}, montre comment la NSA
	peut placer ses backdoors, comment elle les choisirent, 
	et propose plusieurs stratégies de défense \cite{schneier2013NSA}
	pour les vaincre, notamment : \\
	\begin{itemize}
	\item Les vendeurs doivent rendre au minimum le code du chiffrement
	publique (spécifications concernant les protocoles inclus). Le reste
	peut être conservé secret. Afin d'en détecter les vulnérabilités.
	\item La communauté des cryptologues doit pouvoir offrir une version
	compatible et indépendante du système de chiffrement, en open-source
	ou en vente auprès des entreprises privées (pour financer les
	universités par exemple).
	\item Aucun secret! Tout doit être entièrement transparent auprès des
	clients.
	\item L'ensemble des PRNG doivent être rendus conformes avant 
	publication et acceptation.
	\item Aucune fuite d'informations n'est permise, surtout au niveau
	des protocoles de chiffrement. Ceci afin d'éviter la prédiction de
	clés privées.\\
	\end{itemize}
	
	En Septembre 2013, Matthew Green publie un article \cite{green2013NSA}
	sur ce vaste problème entre la NSA et la sécurité cryptographique, qui
	a été salué par plusieurs cryptologues dont B. Schneier.\\
	
	Il précise cependant que ça ne reste que des spéculations, mais
	qu'elles sont nécessaire afin de doubler d'effort dans la sécurité
	de nos communications.\\


	\subsection{Le NIST et l'algo Dual EC DRBG}
	
	Un rapport de Snowden, indique que la NSA a déversé plus de 10.000.000\$ à 
	la compagnie RSA \cite{ravi2013NSA} pour qu'elle utilise ce dernier, 
	et discutable, algorithme comme générateur. \\
	
	On comprend donc mieux les suscipsions autour d'un accord entre le NIST et 
	la NSA pour la publication d'une recommandation de cet algorithme\\	
	
	Les recommandations du NIST en matière de PRNG (qu'ils appelent plutôt 
	DRNG - Determinist Random Number Generation), débute en 2006, la 
	publication du dernier document sur les DRNG date de Janvier 2012 avec la 
	\texttt{SP800-90A} \cite{nist800-90A}:\\

	Ce document présente quatres algorithmes de PRNG qui sont :\\ 
	\begin{itemize}
		\item Le Hash\_DRBG basé sur des fonctions de hachage
		\item Le HMAC\_DRBG basé également sur des fonctions de hachage
		\item Le CTR\_DRBG basé sur du chiffrement par bloc
		\item Le Dual Elliptic Curve Deterministic RBG (ou Dual EC DRBG) basé 
		sur une théorie mathématique\\
	\end{itemize}

	Les trois premiers sont conventionnels, acceptés par toute la communauté 
	des cryptologues, et s'avère efficace car ils générent "suffisamment" 
	d'entropie.\\
	
	Le dernier est très différent des trois autres, dans le sens où il utilise 
	une fonction de chiffrement à sens unique. Certains cryptologues ont 
	démontrés que cet algorithme posséde des failles (d'autres indiquent 
	clairement que c'est une back-door du NIST...).\\
	
	En effet, on peut accepter l'utilisation d'une fonction à sens unique, à 
	condition que le secret utilisé ne soit pas conservé ailleurs (en d'autres 
	termes qu'il soit détruit).\\

	Que faire si le NIST garde le secret des algorithmes permettant 
	d'affaiblir considérablement le Dual EC DRGB, et rendre l'aléatoire 
	prévisible pour qui s'en donne les moyens?\\

	En recoupant plusieurs sources, le doute augmente considérablement.\\

	En 2006, Berry Schoenmakers et Andrey Sidorenko établissent une 
	cryptanalyse du DUAL EC DRGB. \cite{dualecrbg2006berry}\\
	
	En 2007, Dan Shumow et Niels Ferguson furent les premiers à dénoncer le 
	NIST d'avoir placer une backdoor délibérément dans cet algorithme
	\cite{shumow2007nist}.\\
	
	Avant Septembre 2013, tout cela n'était que suspicion, mais depuis le 
	NIST à publié un bulletin de nouvelles recommandations pour les DRNG
	\cite{newRecomendingNist}, et indique (surtout grâce à un forcing de 
	la communauté cryptologue) que le Dual EC DRBG ne doit plus être utilisé 
	pour les raisons suivantes :\\
	\begin{itemize}
		\item La provenance des points par défaut de la courbe elliptique 
		utilisée n'est pas clairement détaillée
		\item La génération de ces courbes n'est pas digne de confiance\\
	\end{itemize}
	\textit{"\textbf{Recommending against the use of SP 800-90A Dual Elliptic 
	Curve Deterministic Random Bit Generation:} NIST strongly recommends that, 
	pending the resolution of the security concerns and there - issuance of SP 
	800-90A, the Dual\_EC\_DRBG, as specified in the January 2012 version of 
	SP 800-90A, no longer be used"}\\

	\subsection{... Et OpenSSL ?}
	
	Maintenant, il faut rechercher l'utilisation de cet algorithme dans les 
	classes d'OpenSSL. La nouvelle recommandation du NIST faisant foi.\\

	Le directeur technique d'OpenSSL : Steve Marques a posté le 19 décembre 
	2013 : "Un bug inusuel a été détecté sur une situation inusuelle". \\
	
	Paul Ducklin apporte une bonne synthèse sur le site NakedSecurity
	\cite{duckin2013openssl}, le titre est clair : "Le bug d'OpenSSL nous
	sauve de l'espionnage".\\
	
	L'implantation du DUAL\_EC\_DRGB dans OpenSSL contient une faille, celle-
	ci causant un arrêt brutal ou un blocage de programme.
	Le bug a toujours été là, et il vient seulement d'être détecté.\\
	
	Heureusement, personne n'a pu utiliser cet algorithme, celui-ci est resté 
	dans les phases de tests, les passant tout de même avec succès.\\

\section{Audits}
	\subsection{Audit 1.1 : Le cas Debian 4.0 et OpenSSL 0.9.8}
		\subsubsection{Normes visées}
			Les normes visées furent la RFC 4086 \cite{rfc4086}
			et le FIPS 140-2 \cite{fips140-2}.
			La première définit le bon fonctionnement d'un RNG, tandis que 
			la deuxième	apporte plutôt des algorithmes réputés sûrs pour 
			la génération d'aléatoire.
		
		\subsubsection{Description de la faille}
			Le 13 Mai 2008, Luciano Bello découvert une faille critique du 
			paquet d'OpenSSL sur les systèmes Debian
			\cite{faille2008linux.org}. Un mainteneur Debian 	
			souhaitant corriger quelques bugs aurait malencontreusement 	
			supprimé une grosse source d'entropie lors de la génération des 
			clés. \\
			
			Il ne restait plus que le PID comme source d'entropie!
			Comme celui-ci ne pouvait dépasser 32.768 (qui le PID maximal
			atteignable), l'espace des clés a été restreint à 264.148 clés
			distinctes.\\
		
			Le 14 Mai 2008, Steinar H. Gunderson démontre qu'en connaissant 
			le secret $k$ d'une signature, on peut retrouver
			la clé privée d'un certificat immédiatement \cite{gunderson2008}.\\
		
			Ce secret $k$ étant généré avec un PRNG prévisible, on peut stocker
			deux signatures utilisant le même $k$, où le prédire directement.\\
		
			Une signature DSA consiste en deux nombres $r$ et $s$ tels que :
			
			$$r = (g^k [p]) [q]$$
			$$s = (k^{-1} * (H(m) + x * r)) [q]$$
		
			La clé publique = $(p, q, g)$, le message en clair = $m$, et 
			$H(m)$ est le fingerprint de $m$ qui est également connu.\\
		
			Attaque \no 1 : En connaissant $k$
			
			$$s * k [q] = (H(m) + x*r) [q]$$
			$$\iff (s * k - H(m)) [q] = x*r [q]$$
			$$\iff ((s*k - H(m))*r^{-1})[q] = x$$
			$$\iff (s*k - H(m))*r^{-1} = x$$
	
			Attaque \no 2 : Deux messages possèdent le même $k$
			
			$$s_1 = (k^{-1} (H(m_1) + x*r)) [q]$$
			$$s_2 = (k^{-1} (H(m_2) + x*r)) [q]$$
			$$\iff s_1 - s_2 = (k^{-1} (H(m_1) - H(m_2)) [q]$$
			$$\iff (s_1 - s_2)*(H(m_1) - H(m_2))^{-1} = k^{-1} [q]$$
			$$\iff On\ connaît\ k \implies Attaque\ 1$$
	
			Pour savoir si une clé SSL, SSH, DNSSEC ou OpenVPN est affectée, 
			plusieurs détecteur de données \cite{dowkd.pl} 
			\cite{openssl-blacklist} de clés faibles sont 
			fournis par l'équipe Security de Debian, en même temps que
			l'avertissement de sécurité \cite{debian2008bug}.\\ 
	
		\subsubsection{Tests}
	
			Nous avons décidé de tester le nombre de certificats vulnérables 
			causés 	par le bug OpenSSL de Debian (qui reste le plus populaire), et
			connaissant la blacklist des clés privés. \\
		
			Les résultats nous montrent que sur 500.000 certificats récupérés, au moins
			\footnote{Le logiciel ne prend pas en compte les clés $\leq$ à 512 bits et 
			celles $\geq$ à 4096 bits, et ne prend en compte que les certificats RSA} 
			769 sont vulnérables.\\
			
			Vous pouvez trouver nos scripts parcourant un fichier contenant un 
			certificat sur chaque ligne, ou un dossier contenant des certificats sous 
			forme de fichiers PEM et nos résultats, dans le dossier consacré à l'audit des clés
			cryptographiques.\\
			
			Le format de nos résultats est : \\
			
			\textbf{COMPROMISED:} \textit{<haché\_du\_certificat>} \textit{<nom
			\_fichier\_corrompu (sous forme d'adresse IP)>}\\
			
			Évidemment, nous ne mettons pas ces résultats sur le net puisqu'il indique 
			très clairement les adresses IP contenant le certificat friable, et sa clé
			privée (que l'on peut facilement retrouvé parmi la courte blacklist).\\
			
			Pour information, parmi les entreprises vulnérables nous trouvons les géants
			IBM et CISCO.
	
		\subsubsection{Implémentation}
						
			\paragraph{Configuration utilisée.}\\
			
			Première version OpenSSL vulnérable : 0.9.8c-1.\\
			Première distribution stable où la vulnérabilité a été corrigé
			OpenSSL 0.9.8c-4etch3 pour Debian/Etch.\\	
			Première distribution de test où la vulnérabilité a été corrigé
			OpenSSL 0.9.8g-9 pour Debian/Lenny.\\
			Première distribution instable où la vulnérabilité a été corrigé
			OpenSSL 0.9.8g-9 pour Debian/Sid.\\
			
						
			\paragraph{Fonction.} \\
			
			La fonction liée à cette norme est accessible sous le paquetage 
			\texttt{openssl/crypto/rand/md\_rand.c}.
			
			
			\begin{lstlisting}[style=customc,caption=md\_rand.c, label=mdrand]
			#ifndef PURIFY
			/*
			 * Don't add uninitialised data.
			 MD_Update(&m, buf, j); /* purify complains */
			 */
			#endif
			\end{lstlisting}
			
			Analysons plus en détail cette faille. 
			La conséquence est le blocage de la graine (seed) que l'on 
			passe ensuite au PRNG.\\
		
			Cette ligne a été commentée par erreur en voulant corriger un
			avertissement soulevé par le compilateur Valgrind sur une valeur
			non initialisé.\\

		\subsubsection{Conclusion}
		
			Tout d'abord, il est fortement recommandé de mettre à jour sa
			version OpenSSL vers une version stable où le bug a été corrigé.
			Puis de regénérer toutes les clés de chiffrements, et de ne plus
			utiliser les certificats corrompus.\\
			Il reste malheureusement beaucoup de certificats (+ de 700) 
			touchés par cette faille et n'ayant toujours pas révoqués leurs
			certificats (la plupart étant valide jusqu'en 2020-2030).
			
	\subsection{Audit 1.2 : Le cas LinuxMintDebianEdition sous Android}
		\subsubsection{Normes visées}
	
			Les normes sont les mêmes que l'Audit 1.1
		
		\subsubsection{Description de la faille}
		
			Récemment, en Août 2013 précisément, un patch de sécurité pour les 
			systèmes Android utilisant la version LinuxMintDebianEdition/OpenSSL, 
			dévoile une réparation du générateur de nombres pseudo-aléatoire (PRNG) 
			qui ne donnait pas suffisamment d'entropie
			\cite{alex2013android} \cite{bochum2013randomly}. \\
			
			Le patch indique que le PRNG de cette version d'OpenSSL utilise dorénavant 
			une combinaison de données plus ou moins prévisibles associées à 
			l'entropie générées par /dev/urandom. \\
			Mais sachant que le PRNG d'OpenSSL utilise lui-même /dev/urandom, on a du 
			mal à comprendre pourquoi en rajouter davantage.\\
		
			Eric Wong et Martin Boßlet apporte la solution sur leur site
			\cite{boblet2013android}, l'erreur 
			provient d'un bug "à la Debian", une simple ligne diffère de la version 
			officielle d'OpenSSL (utilisant SecureRandom) à celle de OpenSSL::Random 
			ce situant dans la fonction ssleay\_rand\_bytes. \\
		
			La conséquence n'est pas aussi lourde que celle de Debian, tout d'abord 
			parce que le système Android est rarement utilisé pour du 
			chiffrement de données sensible, et une attaque par prédiction bien que
			plus rapide qu'une attaque par brute-force, reste infaisable. 
			Mais l'erreur est quand même là. \\
	
		
		\subsubsection{Implémentation}
			
			\paragraph{Configuration utilisée.}\\

			Système Android utilisant la version 1.0.1e d'OpenSSL au 
			niveau de la classe SecureRandom, avec la librairie Java Bridge 
			(fichier JAR)accèdant au PRNG d'OpenSSL, la librairie 
			core/java/com/android/internal/os/ZygoteInit.java pour 
			la parallélisation des processus (fork).\\
			
			OS utilisés Linux Mint Debian Edition (LMDE) et Fedora.
			Le bug concerne l'OS LMDE avec la version OpenSSL 1.0.1e.
			
			\paragraph{Fonction.}\\
			
			La fonction d'OpenSSL mise en cause se situe également
			au niveau de \texttt{openssl/crypto/rand/md\_rand.c}, dans
			la fonction \texttt{ssleay\_rand\_bytes(unsigned char *buf, 
			int num, int pseudo)}.
		
			\begin{lstlisting}[style=customc,caption=ssleay\_rand\_bytes.c,
			 label=ssleayrandbytes]
				#ifndef PURIFY /* purify complains */
				#if 0
				      /* The following line uses the supplied buffer as a small
				       * source of entropy: since this buffer is often uninitialised
				       * it may cause programs such as purify or valgrind to
				       * complain. So for those builds it is not used: the removal
				       * of such a small source of entropy has negligible impact on
				       * security.
				       */
				      MD_Update(&m,buf,j);
				#endif
				#endif
			\end{lstlisting}
			
			On retrouve le même bug de Debian. Le fameux patch supprimant 
			l'entropie d'OpenSSL... 7 ans auparavant, et corrigé en 2008.\\
			
			Alors que l'équipe de développement d'OpenSSL déclare que l'impact
			est faible voir inexistant sur la sécurité. Les systèmes Android, 
			déroge à la règle. La raison est que la mémoire n'est pas initialisé
			sur la version LMDE/OpenSSL 1.0.1e comparé à Fedora/OpenSSL 1.0.1e.\\
			
			La seule source d'entropie n'est que la valeur du PID du processus
			courant, très limité.

		\subsubsection{Conclusion}		
		
			Il est alors recommandé à court terme d'ajouter plus d'entropie à
			notre PRNG sous Android, soit manuellement comme le script Ruby
			d'Eric Wong \cite{boblet2013android}, ou avec les outils cités plus
			haut dans ce document.\\
			
			Sinon, le patch d'OpenSSL \cite{alex2013android} répare également
			l'erreur en rajoutant plus d'aléa, bien qu'une recommandation 
			officielle serait la bienvenue, ainsi qu'une meilleure 
			documentatation, l'erreur survenant régulièrement à cause d'une
			mauvaise interprétation du code qui est complexe et difficile à
			comprendre.\\

			
	\subsection{Audit 1.3 : NetBSD 6.0 et OpenSSH}
		\subsubsection{Norme visée}
		
			Le noyau du système NetBSD s'appuie sur le RNG CTR du NIST, que
			l'on peut trouver dans le NIST-SP-800-90A \cite{nist800-90A} pour
			définir son pool d'entropie.	
		
		\subsubsection{Description de la faille}
		
			Autre faille du même genre sur les systèmes NetBSD 6.0 
			concernant OpenSSH/OpenSSL et datant de Mars 2013
			\cite{alerteBSD2013} \cite{failleNetBSDPatrick}. \\
		
			L'erreur provient d'une insuffisance d'entropie dans le PRNG,
			qui ne tient que sur 32 ou 64 bits (la taille d'un sizeof(int)).
			Un attaquant peut brute-forcer une clé généré par ce PRNG.
		
			Il est probable que les dégâts seront bien moins étendus que 
			lors de l'affaire OpenSSL dans Debian car les systèmes 
			NetBSD 6.0 sont moins fréquents.\\
			
		\subsubsection{Implémentation}
			
			\paragraph{Configuration utilisée.} \\
			
			La vulnérabilité concerne les versions NetBSD 6.0 et NetBSD 6.0.1.
			Elle est réparé sur la version NetBSD 6.0.2 et NetBSD 1.0 
			\cite{diffNetBSD}.\\
			
			Une parenthèse mal placée dans le code du fichier 
			/src/sys/kern/subr\_cprng.c du système rend prévisible l'entropie
			fourni pour la génération des clés.\\
			
			\paragraph{Fonctions.} \\
			
			La fonction vulnérable est accessible via le chemin
			\texttt{/src/sys/kern/subr\_cprng.c}.
			
			\begin{lstlisting}[style=customc,caption=subr\_cprng.c(1),
			 label=subrcprng1]
				if (c->flags & CPRNG_INIT_ANY) {
				#ifdef DEBUG
					printf("cprng %s: WARNING insufficient "
					"entropy at creation.\n", name);
				#endif
					rnd_extract_data(key + r, sizeof(key - r), RND_EXTRACT_ANY);
				} else {
					hard++;
				}
			\end{lstlisting}
			
			Pour la partie concernant la ligne 183: rnd\_extract\_data
			(key + r, sizeof(key - r), RND\_EXTRACT\_ANY);\\
			Le deuxième paramètre devrait être sizeof(key) - r.\\
			
			Dans la version 1.15, cette appel a été corrigé,
			et on utilise une nouvelle fonction nommée
			cprng\_entropy\_try \cite{diffNetBSD} à la place de 
			rnd\_extract\_data.\\
			
			\begin{lstlisting}[style=customc,caption=subr\_cprng.c(2),
			 label=subrcprng2]
			static size_t
 	 		cprng_entropy_try(uint8_t *key, size_t keylen, int hard)
 	 		{
 	        	int r;
 	         	r = rnd_extract_data(key, keylen, RND_EXTRACT_GOOD);
 	         	if (r != keylen && !hard) {
 	            	rnd_extract_data(key + r, keylen - r, RND_EXTRACT_ANY);
 	         	}
 	    		return r;
 	    	}
			\end{lstlisting}

			Cette fonction permet de réduire le nombre d'appels de la
			précédente fonction rnd\_extract\_data.
			Elle prend en argument le niveau d'entropie à atteindre "hard"
			ou "soft" afin de donner respectivement de "bons" bits ou
			"suffisamment" de bits.\\
			

		\subsubsection{Conclusion}
			
			Il est recommandé de passé à une version NetBSD supérieur à 5.1, et
			de de recréer toutes données de chiffrement comme les clés SSH
			ayant étés générées avec ce noyau.\\
			
			Il faut également faire attention au patch de sécurité de Janvier 2013
			qui en tentant de régler le problème a généré une autre erreur produisant
			le même effet.\\
			
			L'erreur ne provient pas directement du code d'OpenSSL.
			Mais ici, OpenSSL se contente de récupérer l'entropie fourni
			sans aucune vérification (fonction RAND\_bytes()).\\
			
			Il est également recommandé d'utiliser /dev/random plutôt que
			/dev/urandom pour avoir une bonne entropie.
			
			On souligne quand même le fait que OpenSSL ne contrôle pas
			son entropie, si l'entropie du système est quasi-nulle les
			clés sont tout de même générées. Un avertissement auprès de
			l'utilisateur serait un minimum.
			
\section{Recommandations sur la conception}
Le NIST propose des recommandations à plusieurs niveaux concernant la conception de la source d'entropie. Nous n'en reporterons ici que les recommandations génériques. Les éléments ci-dessous sont basés 

\subsection{Modélisation et validation}
La source d'entropie doit suivre les exigences suivantes 
\begin{enumerate}
\item Le développeur doit documenter complètement la modélisation de la source d'entropie, incluant toutes les interactions entre les composants. De ce fait, la documentation doit pouvoir justifier en quoi la source d'entropie est de confiance. 
\item Il doit définir de façon précise les limites conceptuelles de sécurité de la source d'entropie, qui doivent elles mêmes être équivalentes à un module cryptographique délimitant un périmètre de sécurité (cf. \textit{Cryptographic module boundary} du FIPS 140).
\item Le développeur doit définir le champ des conditions optimales de fonctionnement du générateur d'entropie.
\item La source source d'entropie doit être possiblement validée suivant les recommandations du FIPS 140, ainsi que les tests s'y référant.
\item Le comportement du bruit de la source doit être documenté, validant en quoi le taux d'entropie ne fluctue pas lors d'une utilisation normale.
\item Dès lors qu'un test de validation n'est pas réussi, la source d'entropie doit immédiatement cesser d'envoyer des données de sortie, et doit notifier à l'application l'erreur rencontrée.\\

Enfin, une recommandation optionnelle : 
\item La source d'entropie doit contenir différent types de bruits pour améliorer le comportement global de la source, et prévenir des tentatives de contrôle externe. Chaque bruit doit vérifier les spécifications du 3.1. 
\end{enumerate}

\subsection{Source d'entropie absolue}
Certains générateurs de bits aléatoire demandent une source d'entropie absolue, à savoir qu'elle approxime une sortie qui est uniformément distribuée et indépendante des autres sorties. 
\begin{enumerate}
\item La chaine de bit générée doit fournir au moins $(1-\epsilon)n$ bits d'entropie, où : 
	\begin{itemize}
	\item $n$ est la taille de chaque sortie
	\item $\epsilon$ tel que : $0\leqslant \epsilon \leqslant 2^{-64}$
	\end{itemize}
\end{enumerate}

\subsection{Bruit de la source}
Le bruit fournit par la source doit suivre les recommandations suivantes :
\begin{enumerate}
\item Le bruit doit avoir un comportement probabiliste et ne doit en aucun cas être définissable par quelconque algorithme ou règle.
\item Le développeur doit pouvoir documenter l'opération sur le fonctionnement du bruit de la source, en montrant en quoi le choix de ce bruit fournit une sortie d'entropie acceptable. Ceci comprend le référencement d'articles de recherche et autre littérature pertinente.
\item Le bruit de la source doit pouvoir être testable, de telle sorte que l'on puisse s'assurer qu'il effectue l'opération attendue. Il doit donc être possible de récupérer des données sur la source de bruit sur lesquels on puisse lancer la batterie de tests. La récupération des données sur la source de bruit ne doit en aucun cas altérer le comportement du bruit, ou de la sortie.
\item Toute défaillance du bruit doit être rapidement détectable. Les méthodes de détection doivent être documentées.
\item La documentation de la source du bruit doit également décrire sous quelles conditions le bruit est connu pour mal fonctionner. Ceci consiste ainsi à répertorier les environnements dans lesquels la source peut fonctionner correctement. 
\item La source de bruit doit être protégée au maximum contre toute attaque/tentative de conditionnement ou simple connaissance de fonctionnement de la part d'un adversaire. 
\end{enumerate}

\subsection{Composant de conditionnement}
Le composant de conditionnement doit suivre les recommandations suivantes :
\begin{enumerate}
\item Le développeur doit documenter si la source d'entropie nécessite ou non un conditionnement. 
\item La méthode de conditionnement doit être décrite et argumentée. Elle doit en effet expliciter en quoi elle permet de diminuer l'alignement d'une source de bruit, ou en quoi la sortie créée correspond à l'entropie attendue
\item La méthode de conditionnement doit pouvoir être validée par des tests
\item Le développeur doit pouvoir estimer l'alignement en sortie de conditionnement. 
\item Le développeur doit prévoir une documentation expliquant le comportement de la méthode de conditionnement en cas de variation de comportement de la part de la source de bruit.
\end{enumerate}

\subsection{Batterie de tests}
Globalement, les tests doivent suivre les recommandations suivantes :
\begin{enumerate}
\item Les tests doivent être effectués au démarrage puis de façon continuelle pour s'assurer que les composants du générateur d'entropie fonctionnent correctement.
\item Tous les tests doivent être documentés, en particulier sur les conditions sous lesquels ils doivent être exécutés, les résultats attendus pour chacun de ceux-ci, et une explication rationnelle indiquant en quoi chaque test est approprié pour la détection de dysfonctionnement de la part de la source d'entropie. 
\end{enumerate}

\subsubsection{Tests sur le bruit}
Les tests sur le bruit sont pour la plupart du temps dépendants de la technologie utilisée. Dans la majorité des cas, il faut tester via des procédures traditionnelles de tests (type test monobit, test du $\chi_2$, et tests d'exécution) si celui-ci est bien non biaisé et produit des données indépendantes.
\begin{enumerate}
\item Au minimum, des tests continus doivent être implémentés, et ceci de façon indépendante. Le développeur doit de plus documenter toutes les sources de défaillance.
\item Les tests sont implémentés sur les données binaires récupérées via le bruit source.
\item La source de bruit doit être testé dans son ensemble (suivant la variation du bruit).
\item Le bruit généré durant la démarrage ayant passé avec succès les tests de démarrage peut être utilisé pour produire de l'entropie.
\item Lorsqu'un test est échoué, le générateur doit en être notifié.\\

Optionnel : 
\item Une étude peut être requise sur les bords du bruit bruit généré, dans les cas ou le comportement du générateur est altéré.
\end{enumerate}


\subsubsection{Tests sur le conditionnement}
Le rôle du conditionnement est de réduire l'alignement  présent chez certaines sources d'entropie afin de s'assurer que l'entropie est construite à un taux acceptable. Les recommandations sont les suivantes :
\begin{enumerate}
\item Les composants de conditionnements doivent être testés dès le démarrage, afin d'être certain que le générateur fonctionne comme prévu
\item Le développeur doit documenter les tests implémentés et inclure les conditions d'échecs pour chacun d'entre eux.
\end{enumerate}



\section{Tests effectifs sur l'entropie fournie par les sources d'entropie}

\subsection{Déterminer si les données sont IID}

\paragraph{Définition.\\}
On dit que des variables sont \textbf{IID} (indépendantes et identiquement distribuées) si elle suivent toute la même loi de probabilité et si elles sont mutuellement indépendantes. \\

Les tests suivants ont été conçus pour montrer si les données en sortie du bruit et/ou en sortie du conditionnement sont bien IID, ceci en effectuant des tests sur la distribution des données. Le but est de vérifier l'hypothèse $H_0$. Pour la vérifier, nous allons considérer ici deux types de tests : 
\begin{itemize}
\item Des tests de répartition aléatoire sur l'ensemble
\item Des tests statistiques\\
\end{itemize}

Si un des tests est passé, alors on passe au suivant. La défaillance d'un seul des tests impliquera le caractère non IID des données. 


\subsubsection{Tests sur l'indépendance et la stabilité}
Nous travaillons sur le test statistique bilatéral suivant : 
\begin{itemize}
\item l'hypothèse $H_0$ : "Les données sont IID". 
\item l'hypothèse $H_1$ : "Les données ne sont pas IID". \\

\end{itemize}


Suivant un jeu de données $(|donnees|=n)$, on divise celui-ci en 10 sous ensemble de tailles égales ($\frac{N}{10}$). On effectue enfin nos tests sur chacune de ces données. La stratégie de test est effectuée comme suit : 
\begin{enumerate}
\item On calcule tout d'abord différents scores statistiques parmi les suivants :
	\begin{itemize}
	\item Score de compression, un score par sous ensemble de données
	\item Score \textit{Over/Under Runs}, deux scores par sous ensemble
	\item Score excursion, un score par sous ensemble
	\item Score \textit{Runs} directionnel, trois scores par sous ensemble
	\item Score de covariance, un score par sous ensemble 
	\item Score de collision, trois scores par sous ensemble\\
	\end{itemize}
	
\item Pour chaque calcul de score : 
	\begin{enumerate}
	\item On stocke pour chaque type de score les résultats dans un vecteur de $J$ scores
	\item On répète les étapes suivantes 1000 fois :
		\begin{enumerate}
		\item On permute les sous ensembles précédents en utilisant un générateur pseudo aléatoire, suivant l'algorithme de permutation  \textit{Fisher–Yates shuffle}. 
		\item On calcule les nouveaux scores suivant cette nouvelle organisation de sous-ensembles
		\item On récupère ce vecteur de $J$ scores
		\end{enumerate}
	\item On classifie les scores de 2a) en le comparant avec tous les scores liés permutés. Par exemple, si le score des données originelles est plus grand que tous ceux des permutations, alors ce premier a le score de 1000, et les répertoires permutés on un score inférieur à 1000. Il est possible que les données permutées aient le même score. Lorsque le score originel est le même que certains de scores des données permutées, on considère le score en récupérant celui le plus proche de la médiane. \\
	
Plus généralement, étant donné : 
		\begin{itemize}
		\item Un score $S$
		\item Une liste de scores des données permutées $L$
		\end{itemize}
	On détermine le \textbf{rang de $S$} tel que : 	
	
	$$
	Rang(S) = \left\{
		\begin{array}{llllll}
		max(j) & \text{tel que} & L[j] \leqslant S,& si& L[500]>S & (1)\\
		500 & &si& L[500]=S & (2)\\ 
		min(j) & \text{tel que} & L[j] \geqslant S,& si& L[500]<S & (3)\\
		\end{array}			
	\right.
	$$ 
	\newline	
	
		\begin{enumerate}	
		\item Exemple cas (1) :
			\begin{itemize}
			\item Soit $S=20$ et $L[500]=22$. On est dans le cas (1). On va chercher le $max(j)$ tel que $ L[j] \leqslant S$.
			\item On a $L[299]=19$, $L[300]=20$, $L[301]=20$, $L[302]=22$.
			\item On retourne au score $301$, ainsi $Rang(S)=301$.\\
			\end{itemize}
			
		\item Exemple cas (3) :
			\begin{enumerate}
			\item Soit $S=20$ et $L[500]=18$. On est dans le cas (3). On va chercher le $max(j)$ tel que $ L[j] \geqslant S$.
			\item On a $L[599]=19$, $L[600]=20$, $L[601]=20$.
			\item On retourne au score $600$, ainsi $Rang(S)=600$.\\
			\end{enumerate}
			
		\end{enumerate}
	\end{enumerate}
	
\item Le rang alors obtenu est considéré comme une \textit{p-value} pour un test bilatéral. Pour rappel, une \textit{p-value} est la probabilité d'obtenir la même valeur de test si l'hypothèse nulle est vraie. Ainsi, on compte pour chacun des 6 tests un ensemble de $10*J$ \textit{p-values}.\\

\item On gère enfin les \textit{p-values} de la façon suivante : 
	\begin{enumerate}
	\item Tous les rangs compris entre 50 et 950 sont relevés. Ces événements ont une probabilité d'arriver de 10\% au total. 
	\item Si le nombre de rangs relevés est supérieur ou égal à 8, on considère le test comme échoué.
		\begin{enumerate}
		\item Si le test est effectué sur la source du bruit, alors celle-ci n'est pas considérée comme IID
		\item Si le test est effectué sur le conditionnement, alors  la source d'entropie n'est pas validée.
		\end{enumerate}
	\end{enumerate}
\end{enumerate}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node 	(titre) 		[]{\textbf{Test $t$}};
\node	(donnees) 	[process,below of=titre,yshift=1cm, xshift=6cm]	{Données (taille $n$)};
\node	(n101) 		[process,below of=donnees,xshift=-3cm]	{$\frac{n}{10}$};
\node	(n102) 		[process,below of=donnees,xshift=3cm]	{$...$};
\node	(n1010) 		[process,below of=donnees,xshift=9cm]	{$\frac{n}{10}$};
\node	(permut) 	[process,below of=n101,xshift=2cm]	{$permutation$};
\node	(ini) 		[process,below of=n101,xshift=-2cm]	{$score_t^{ini}$};
\node	(score) 		[process,below of=permut]	{$score_t[j]$};	
\node 	(dec) 		[decision, below of=score,yshift=-0.4cm] {$j<1000$}; 
\node 	(rangs) 		[process, below of=dec,yshift=-0.4cm] {$rangs[j]$}; 
\node 	(dec2) 		[decision, below of=rangs,yshift=-0.4cm] {$Out>8$}; 
\node 	(fail) 		[below of=dec2, yshift=-0.4cm] {Test échoué}; 
\node 	(reussi) 	[right of=dec2,xshift=3cm] {Test réussi}; 

\begin{pgfonlayer}{background}
\node[punkt, fit=(titre)(donnees)(n101)(n102)(n1010)(permut)(ini)(score)(dec)(rangs)(dec2)(fail)(reussi), fill=yellow!5] (groupclient) {};
\end{pgfonlayer}

\draw	[arrow]		(donnees)	-|		(n101);
\draw	[arrow]		(donnees)	-|		(n102);
\draw	[arrow]		(donnees)	-|		(n1010);
\draw	[arrow]		(n101) 	-|	node[anchor=west] {$j=0$}	(permut);
\draw	[arrow]		(n101)	-|		(ini);
\draw	[arrow]		(permut)	--	node[anchor=west] {$j++$}	(score);
\draw	[arrow]		(score)	--	(dec);
\draw 	[arrow]		(dec) --++ (+3,0) node [near start,anchor=south] {vrai} |- (permut);
\draw	[arrow]		(dec)	-- node[near start,anchor=west] {faux}	(rangs);
\draw	[arrow]		(ini)	|-	(rangs);
\draw	[arrow]		(rangs)	--	(dec2);
\draw	[arrow]		(dec2)	-- node[near start,anchor=west] {faux} (fail);
\draw	[arrow]		(dec2)	-- node[near start, anchor=south] {vrai} (reussi);

\end{tikzpicture}
\end{center}
\caption{Structure de validation de données $d$ par un test $t$. $Out$ vaut "$|Rangs\leq 50$ \&\& $Rangs \geq 950|$"  }
\end{figure}

%\node 	(source)		[process,below of=titre,yshift=1cm, xshift=0.5cm]	{Source d'entropie};
%\node 	(conver)		[process,below of=source,xshift=1cm]		{Convertisseur};
%\node 	(bz2) 		[process,right of=conver, xshift=5cm]	{BZ2};
%\node	(score)		[right of=bz2, xshift=2cm] {Score};
%
%\begin{pgfonlayer}{background}
%\node[punkt, fit=(titre)(source)(conver)(bz2)(score), fill=yellow!5] (groupclient) {};
%\end{pgfonlayer}
%
%\draw	[arrow] (source)		-- node[anchor=west] {144 21 139 0 0 15}		(conver);
%\draw	[arrow] (conver)		-- node[anchor=north] {"144,21,139,0,0,15"}		(bz2);
%\draw	[arrow] (bz2)		-- node[anchor=north] {21}		(score);


\subsubsubsection{Score de compression}
Les algorithmes de compressions sont habituellement bien adaptés pour supprimer les données redondantes des chaînes de caractère. Suivant un algorithme de compression choisi, le score de compression est la longueur de la donnée compressée obtenue. 

\paragraph{Calcul du score.\\}
Le score est calculé de la façon suivante :
\begin{enumerate}
\item Les sous ensembles de données sont encodés en chaîne de caractère séparés par une virgule
\item La chaîne de caractère est compressée suivant l'algorithme de compression de bzip2 \footnote{cf. \url{www.bzip.org}}
\item Le score retourné correspond à la longueur de la chaîne de caractère compressée
\end{enumerate}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node 	(titre) 		{\textbf{Score de compression}};
\node 	(source)		[process,below of=titre,yshift=1cm, xshift=0.5cm]	{Source d'entropie};
\node 	(conver)		[process,below of=source,xshift=1cm]		{Convertisseur};
\node 	(bz2) 		[process,right of=conver, xshift=5cm]	{BZ2};
\node	(score)		[right of=bz2, xshift=2cm] {Score};

\begin{pgfonlayer}{background}
\node[punkt, fit=(titre)(source)(conver)(bz2)(score), fill=yellow!5] (groupclient) {};
\end{pgfonlayer}

\draw	[arrow] (source)		-- node[anchor=west] {144 21 139 0 0 15}		(conver);
\draw	[arrow] (conver)		-- node[anchor=north] {"144,21,139,0,0,15"}		(bz2);
\draw	[arrow] (bz2)		-- node[anchor=north] {21}		(score);
\end{tikzpicture}
\end{center}
\caption{Calcul du score de compression}
\end{figure}

\subsubsubsection{Scores \textit{Over/Under Runs} (2)}
\paragraph{Définition.\\}
On définit le \textbf{\textit{run test}} comme la série des valeurs montantes ou la série des valeurs décroissantes. Le terme de \texttt{run} peut être expliqué comme la successions d'éléments de la même classe. Le nombre d'augmentations ou de réductions définit la longueur du test.  Dans un jeu de données aléatoire, la probabilité que la $(i+1)$ème valeur est plus grande ou plus petite que la $i$ème valeur doit suivre la loi binomiale.\\

Le \textit{run test} est défini tel que : 
\begin{itemize}
\item $H_0$ : la séquence a été produite de manière aléatoire
\item $H_1$ : la séquence n'a pas été produite de manière aléatoire
\item Test statistique : 
	$$ Z = \frac{R - \overline{R}}{s_R}$$
	où : 
	\begin{itemize}
	\item $R$ : le nombre de \textit{runs} observés
	\item $\overline{R}$, la moyenne (le nombre de runs attendus) telle que  :
	$$\overline{R}= \frac{2  N_+ N_-}{N}+1$$
	\item $s_R$ la variance (déviation standard) calculée telle que : 
	$$s_R^2 = \frac{2 N_+ N_-(2N_+ N_- -N)}{N^2(N-1)}  = \frac{(\overline{R}-1)(\overline{R}-2)}{N-1}$$
	\end{itemize}
\item Niveau significatif : $\alpha$
\item Zone critique : Le \textit{run test} rejette l'hypothèse nulle $H_0$  si $ |Z| > Z_{1-\alpha/2}$


\end{itemize}





\paragraph{Exemple de Run test.\\}
Soit la suite binaire $X=(x_1,x_2,...,x_n)$ sortie d'un générateur aléatoire. Pour tous les $i$ allant de $1$ à $n-1$. On stocke dans un vecteur de taille $n-1$ le signe de $x_{i+1}-x_i$. Le nombre de run consiste au nombre de changements de signe.

Si $X=111001111000110$, alors son vecteur associé sera $(++-+++++-++++-)$, soit 6 \textit{runs}. Dans le cas des suites binaires, il s'agit simplement de compter le nombre de changement d'éléments (ou classes), l'ensemble de données étant $\lbrace 0,1 \rbrace$. Si l'élément $i$ est équivalent au précédent, alors on passe au suivant, sinon on incrémente de un le nombre de \textit{runs}.\\

Ici on a donc : 
\begin{itemize}
\item $R = 6$
\item $\overline{R}= \frac{2*3*3}{15}+1 = 2.2 $
\item $s_R^2 = \frac{1.2*0.2}{14} = 0,017142857$
\item D'où $ Z = \frac{6 -2.2}{0,130930734} = 29.0229794$
\item On choisit un niveau $\alpha=0.05$
\item On cherche $Z_{1-\alpha/2}$. $\frac{1-\alpha}{2}=0.475$ soit suivant la courbe normale une valeur de  $Z_{1-\alpha/2}=1.96$. Ceci correspond à la valeur critique. La zone de rejet de $H_0$ est telle que $|Z| > 1.96$
\item Étant donné que $|Z| > 1.96$, on en conclu que les données ne sont pas aléatoires au risque de 5\%.\\

\end{itemize}


\paragraph{Calcul des scores \textit{Over/Under Runs}.\\}
Pour chaque sous-ensemble, on calcule la médiane des données. On identifie ensuite les données en 3 sous-ensembles :
\begin{itemize}
\item Soit elles sont égales à la médiane
\item Soit elles sont inférieures à la médiane
\item Soit elles sont supérieures à la médiane
\end{itemize}
Les sous ensembles inférieurs et supérieurs à la médiane sont susceptible d'avoir un \textit{run score} relativement faible, si les données sont suffisamment bien IID.\\

 
Les deux scores de \textit{over/under runs} sont calculés comme suit : 
\begin{enumerate}
\item On récupère la médiane de notre sous ensemble de données. Pour des données binaires, la médiane sera de 0.5
\item Pour chaque sous ensemble original et chaque sous ensemble permuté, un sous ensemble temporaire est construit comme suit. Pour chaque élément : 
	\begin{enumerate}
	\item Si l'élément est plus grand que la médiane, on ajoute \texttt{+1} au vecteur temporaire
 	\item Si l'élément est plus petit que la médiane, on ajoute \texttt{-1} au vecteur temporaire
	\item Si l'élément est égal à la médiane, on passe à l'élément suivant	
	\end{enumerate}
\item La plus grande  taille du \textit{run} sur les \texttt{+1} ou les \texttt{-1} est considéré comme le premier score 
\item La taille du \textit{run} sur les \texttt{+1} et les \texttt{-1} est considéré comme le second score.
\end{enumerate}

\paragraph{Exemple.\\}
Considérant l'ensemble de taille 7 ayant les données suivantes : $\lbrace 5,15,12,1,13,9,4\rbrace$.
\begin{enumerate}
\item  On récupère la médiane : $9$
\item  Création du vecteur temporaire : $5<9 \Rightarrow -1 ...$. Vecteur final : $\lbrace -1, +1,+1,-1,+1,-1 \rbrace$. On note que pour ce vecteur la valeur 9 a été omise.
\item Le \textit{run} le plus long pour le \texttt{+1} et le \texttt{-1} est de taille 2, (score 1)
\item Le \textit{run} global est de taille 5, (score 2)
\end{enumerate}

\subsubsubsection{Score excursion}
Le score d'excursion mesure la déviation en chaque point d'une somme d'éléments suivant leur moyenne.

\paragraph{Définition.\\}
 Étant donné les éléments $(s_0,s_1,...,s_i)$, et leur moyenne $\mu_i$,  \textbf{l'excursion} $Esc_i$ est définie telle que :
 $$ Esc_i= s_0+ s_1 + ... + s_i - i*\mu$$ 
Le score retourné est l'excursion maximale en valeur absolue du sous ensemble de données. \\

\paragraph{Calcul du score.\\}
Le score est ainsi calculé comme suit. $\mu$ est défini comme la moyenne des valeurs d'un ensemble donné.
\begin{enumerate}
\item Pour $j=1$ à $ \lfloor\frac{N}{10}\rfloor$ (taille des données du sous ensemble), on calcule $d_j=|Esc_j| = |\sum\limits_{i=0}^{j} s_i|$
\item $\text{Score} = \Max\limits_{j=0,j<=\lfloor\frac{N}{10}\rfloor} (d_j)$
\end{enumerate}

\paragraph{Exemples.\\}
Étant donné le sous ensemble suivant : $ \lbrace 2, 15, 4, 10, 9 \rbrace$. 
\begin{enumerate}
\item On calcule $\mu$, ici $\mu=8$
\item Calcul des $d_j$ :\\
$d_1=|2-8|=6$, $d_2=|2+15-2*8|$, $d_3=3$, $d_4=1$, $d_5=0$
\item Le score est donc de $6$\\
\end{enumerate}

\subsubsubsection{Scores Runs directionnel (3)}
Le principe du run test reste le même que celui évoqué précédement à l'exception suivante près:  lorsqu'il y a égalité entre deux éléments consécutifs, on le référence comme étant 0 dans le vecteur temporaire plutôt que de passer directement à l'élément suivant. 

\paragraph{Calcul des scores pour des données quelconques.\\}
Le score est calculé de la façon suivante : 
\begin{enumerate}
\item Le nombre total de runs (sans considérer le 0 comme un changement de "signe") (score 1)
\item La longueur du plus long run (les 0 sont également ignorés)  (score 2)
\item Le maximum entre le nombre de données \texttt{+1} et le nombre de données \texttt{-1} (score 3)\\

\end{enumerate}


\textbf{Exemple :} \\
Étant donné l'ensemble suivant : $\lbrace 2, 2, 2, 5, 7, 7, 9, 3, 1, 4, 4 \rbrace$. 
\begin{enumerate}
\item  On calcule son vecteur temporaire lié $ \lbrace 0, 0, +1, +1, 0, +1, -1, -1, +1, 0 \rbrace $
\item Nous comptons 3 séries de run : $(0,0,+1,+1,0,+1)$, $(-1,-1)$ et $(+1,0)$ (score 1)
\item Le run le plus long est de $4$ : $(+1,+1,0,+1)$ (score 2)
\item On compte 4 \texttt{+1} et 4 \texttt{-1}, le maximum des deux est donc de 4 (score 3).
\end{enumerate}


\paragraph{Données binaires.\\}
Dans le cadre des données binaires en sortie de source d'entropie, il convient de faire un pré-traitement sur les données : 
\begin{enumerate}
\item On convertit les bits en bytes.
\item On calcule le poids de hamming pour ces éléments : \\
Pour $i=0$ à  $\frac{\lfloor\frac{N}{10}\rfloor}{8} -1 $, on stocke dans $W_i$ son poids de Hamming, tel que $W_i=hamming\_weight(s_i,...,s_{i+7})$
\item On réitère l'opération des données quelconques à partir de ce vecteur $W_i$.
\end{enumerate}

\paragraph{Poids de Hamming.\\}
Le \textbf{poids de hamming} d'un sous ensemble $(s_i,...,s_{i+n})$ , donné par $hamming\_weight(s_i,...,s_{i+n})$ est défini comme le nombre de 1 de la suite $(s_i,...,s_{i+n})$.



\subsubsubsection{Score de covariance}
Le score de covariance permet de détecter la relation entre les valeurs numériques successives. En effet, toute relation linéaire entre des paires successives va affecter directement ce score. On pourra alors constater une différence entre la covariance calculée sur le sous ensemble de données originales et la covariances calculée sur le sous ensemble de données permutées. La covariance est calculée entre chaque paire consécutive du sous ensemble S tel que $s_i$ est apparié avec $s_{i+1}$.\\

\paragraph{Calcul du score.\\}
Le score est calculé comme suit : 
\begin{enumerate}
\item la variable $count$ est initialisée à 0.
\item $\mu$, moyenne des données de $s_0$ à $s_{\lfloor\frac{N}{10}\rfloor-1}$ est calculée.
\item Pour $i=1$ à $\lfloor\frac{N}{10}\rfloor$ on incrémente $count$ tel que :
$$count = count + (s_i - \mu)(s_{i-1} - \mu)$$
\item On obtient enfin le score : $Score = \lfloor \frac{count}{\lfloor\frac{N}{10}\rfloor-1} \rfloor$
\end{enumerate}

\paragraph{Exemple.\\}
Étant donné le sous-ensemble  : $\lbrace 15, 2 ,6 , 10; 12 \rbrace$ de 5 éléments :
\begin{enumerate}
\item $\mu = 9$
\item 	\begin{itemize}
		\item Pour $i=1$, $count =0 + (2-9)(15-9) = -42$
		\item Pour $i=2$, $count = -42 + (6-9)(2-9) = -21$
		\item Pour $i=3$, $count = -24$
		\item Pour $i=4$, $count = -21$
		\end{itemize}
\item $Score = \lfloor \frac{-21}{4} \rfloor = -5$
\end{enumerate}

\subsubsubsection{Score de collision (3)}
Une façon naturelle de tester l'entropie d'un générateur est de mesurer le nombre d'essais nécessaires pour obtenir une valeur identique à la première, en d'autres termes, le nombre d'essais nécessaires pour obtenir une collision. Ainsi,  notre score de collision va mesurer le nombre d'essais successifs jusqu'à ce qu'un élément identique soit trouvé.\\


Dans le cas des données binaires, un sous ensemble de données binaires est converti en séquence de 8bits avant d'être testé. \\

\paragraph{Calcul des scores.\\}
Les 3 scores de collisions sont calculés comme suit : 
\begin{enumerate}
\item $Counts$  est une liste d'échantillons nécessaires pour trouver une collision. La liste est vide à l'initialisation.
\item $pos=0$
\item Tant que $pos < \lfloor\frac{N}{10}\rfloor$
	\begin{enumerate}
	\item Trouver le plus petit $j$ tel que $s_{pos} ... s_{pos+j}$
		\begin{enumerate}
		\item Si aucun $j$ de ce type n'existe, on sort de la boucle tant que
		\end{enumerate}
	\item Ajouter $j$ à la liste $Counts$
	\item $pos = pos + j + 1$
	\end{enumerate}
\item On retourne les scores suivants : 
	\begin{enumerate}
	\item La valeur minimale de la liste $Counts$ (score 1)
	\item La moyenne de la liste $Counts$ (score 2)
	\item La valeur maximale de la liste $Counts$ (score 3)
	\end{enumerate}
\end{enumerate}

\paragraph{Exemple.\\}
Considérant les données : $ \lbrace 2, 1, 1, 2, 0, 1, 0, 1, 1, 2 \rbrace$ de taille $10$.
\begin{enumerate}
\item On exécute le contenu de la boucle tant que : 
	\begin{enumerate}
	\item Considérant $2$ comme la $0$e valeur, la première collision apparaît à $j=2$, pour la valeur \texttt{1}.
	\item On passe à une analyse sur le reste de l'ensemble initial non analysé : $ \lbrace 2, 0, 1, 0, 1, 1, 2 \rbrace$. La première collision de ce sous-ensemble apparaît en $j=3$, pour la valeur \texttt{0}.
	\item On travaille à présent sur l'ensemble  $ \lbrace  1, 1, 2 \rbrace$. La première collision apparaît en $j=1$
	\item Enfin, on ne trouve aucune collision sur l'ensemble $\lbrace 2 \rbrace $
	\end{enumerate}
\item On retourne les scores : 
	\begin{enumerate}
	\item $min(Counts) = 1$ (score 1)
	\item $\mu_{Counts} = 2$ (score 2)
	\item $Max(Counts) = 3$ (score 3)
	\end{enumerate}

\end{enumerate}

\subsubsection{Test statistique spécifique : \chidpdf}
Dès lors que source d'entropie est considérée comme IID, alors la distribution de ces valeurs peut être considérée comme une distribution indépendante, une distribution multinomiale.

\paragraph{Définition.\\}
La \textbf{loi multinomiale} est une généralisation de la loi binomiale. On considère $m$ résultats possibles (2 pour la loi binomiale). Soit $N_i$ pour $i \in \lbrace1,...,m\rbrace$ la variable aléatoire multinomiale ayant une probabilité $p_i$, telle que :
\begin{center}
$ \sum \limits_{i=1}^{m} N_i = 1$ et  $\sum \limits_{i=1}^{m} p_i = 1$ 
\end{center}
La densité de probabilité de cette loi s'écrit : 
$$ \mathbb{P}(N_1=n_1, ..., N_m = n_m) = \frac{n!}{n_1! ... n_m!}p_1^{n_1}...p_m^{n_m}$$
Pour respectivement les espérances et variances suivantes :
\begin{center}
$ \mathbb{E}[N_i]=np_i$ et $\mathbb{V}[N_i]=np_i(1-p_i)$
\end{center}

\paragraph{Approximation.\\}
Si les variables sont indépendantes, $\sum \limits_{i=1}^m \frac{(N_i - np_i)^2}{np_i(1-p_i)}$ suit une loi du \chidpdf à $m$ degrés de libertés. Ainsi, le test du \chidpdf peut ici être utilisé pour tester si des données suivent une distribution multinomiale.\\


Plus généralement, le test peut être utilisé pour vérifier si des données suivent une distribution particulière, pourvu que celles-ci ne soient pas de trop grande taille. Deux types de tests sont proposés sur la source d'entropie : 
\begin{itemize}
\item Le test d'indépendance entre des données successives obtenues (tests différents pour des données binaires et non binaires)
\item Le test d'ajustement sur les 10 sous-ensembles de données, qui permet de vérifier si le modèle adopté pour les données est satisfaisant, ie. dans quelle mesure les résidus sont dus au hasard (tests différents pour des données binaires et non binaires). 

Nous ne détaillerons pas dans ce rapport ces tests respectifs. Ils sont toutefois décrits dans le document du NIST SP800-90b.

\end{itemize}



\subsection{Déterminer l'entropie minimale des sources IID}
On souhaite à présent estimer l'entropie fournie par une source IID (données indépendantes et identiquement distribuées). 
Ce test est basé sur le nombre d'observations d'un échantillon le plus courant de la source de bruit ($pmax$). Le but est de calculer la borne minimale d'entropie de la source.\\

\paragraph{Calcul de l'entropie minimale.\\}
Étant donné N échantillons $\lbrace x_1, ... x_n \rbrace$
\begin{enumerate}
\item Trouver la valeur la plus souvent rencontrée dans le jeu de données
\item Compter le nombre d’occurrences de cette valeur, stocké dans $C_{MAX}$
\item Calculer  $pmax= \frac{C_{MAX}}{N}$
\item Calculer $C_{BOUND} = C_{MAX} + 2.3 \sqrt{N*pmax(1-pmax)} $
\item Calculer $ H = -log_2(\frac{C_{BOUND}}{N})$
\item Calculer le nombre d'éléments dans l'échantillon, que l'on stocke dans W. 
\item $min(W,H)$ est l'entropie minimale
\end{enumerate}


\paragraph{Exemple.\\}
Considérant le jeu de données  $\lbrace 0,1,1,2,0,1,2,2,0,1,0,1,1,0,2,2,1,0,2,1 \rbrace$ de 20 données :
\begin{itemize}
\item La valeur la plus courant du jeu de données est \texttt{1} (On compte 6 \texttt{0}, 8 \texttt{1} et 6 \texttt{2})
\item $C_{MAX} = 8$
\item $pmax = \frac{8}{20} = 0.4$
\item $ C_{BOUND} = 8 + 2.3 \sqrt{20*0.4*0.6} = 13.04$
\item $ H = -log_2(\frac{13.04}{20}) = 0.186$
\item $ W = 3$
\item Entropie minimale calculée : $ min(3,0.186) = 0.186$
\end{itemize}

