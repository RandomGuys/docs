\chapter{Entropie}
\section{Définitions et contexte}

\subsection{Introduction}
Cette partie explicite les notions d'entropie nécessaires pour la définition d'aléatoire de certains programmes, mais décrit aussi les sources qui de génération de bits aléatoires et les tests liés. \\



Trois axes principaux sont nécessaires à la mise en place d'un générateur cryptographique aléatoire de bits  : 
\begin{itemize}
\item Une source de bits aléatoires (source d'entropie)
\item Un algorithme pour accumuler ces bits reçus et les faire suivre vers l'application en nécessitant.
\item Une méthode appropriée pour combiner ces deux premiers composants\\
\end{itemize}


\subsection{Estimation de l'entropie générée par la source}
Il est tout d'abord important de vérifier que la source d'entropie choisie produit suffisamment d'entropie, à un taux égalant voire dépassant une borne fixée. Pour ce faire, il faut définir avec précision la quantité d'entropie générée par la source. Il est de plus important de considérer les différents comportements des composants de la source, afin d'éliminer les interactions qu'ils peut y avoir entre les composants. En effet, ceci peut provoquer une redondance dans la génération d'entropie si cela n'est pas considéré. Étant donné une source biaisée, l'entropie générée sera conditionnée et donc plus facilement prévisible/estimable.

La source d'entropie doit donc être minutieusement choisie, sans qu'aucune interaction et conditionnement ne soit possible.

\subsection{Concept d'entropie}
\paragraph{Définition.\\}
Soit $X$ est une V.A. discrète. On définit l'\textbf{entropie} de $X$ comme suit : 
$$H(X) = - \sum_x P(X=x)*log(P(X=x))	 $$ 
Le logarithme est dans notre cas de base 2. L'entropie se mesure en shannons ou en bits.\\

\paragraph{Définition.\\}
On définit le \textbf{désordre} (ou incertitude) étant liée à cette expérience aléatoire. Si l'on considère l'ensemble fini des issues possibles d'une expérience $\lbrace v_1,...,v_n \rbrace$, l'entropie de l'expérience vaudra :
$$H(\epsilon) = - \sum_x P(\lbrace a_i \rbrace)*log(P(\lbrace a_i \rbrace))	 $$ 

\paragraph{Propriété.\\} 
On constate que l'entropie est maximale lorsque X est équi-répartie. En effet, si l'on considère n éléments de X étant équi-répartie, on retrouve notre entropie de $H(X) = log(n)$. \\


Ainsi, on comprend qu'une variable aléatoire apporte en moyenne un maximum d'entropie lorsqu'elle peut prendre chaque valeur avec une équiprobabilité. D'un point de vue moins théorique, on considère que plus l'entropie sera grande, plus il sera difficile de prévoir la valeur que l'on observe.

\paragraph{Min-entropy.\\}
La recommandation du NIST propose le calcul de \textit{Min-entropy} pour mesurer au pire des cas l'entropie d'une observation. \\

Soit $x_i$ un bruit de la source d'entropie. Soit $p(x_i)$ la probabilité d'obtenir $x_i$. On définit l'entropie au pire des cas telle que : 
$$\text{Min-entropy}=-log_2(max(p(x_i))$$
La probabilité d'observer $x_i$ sera donc au minimum  $\frac{1}{2^\text{Min-entropy}}$.

\subsection{Source d'entropie}
\paragraph{Approche théorique.\\}
La source d'entropie est composée de 3 éléments principaux : 
\begin{itemize}
\item le \textbf{bruit source}, qui est la voûte de la sécurité du système. Ce bruit doit être non déterministe, il renvoie de façon aléatoire des bits grâce à des processus non déterministes. Le bruit ne vient pas nécessairement directement d'éléments binaires. Si ce bruit est externe, il est alors converti en données binaires. La taille des données binaires générées est fixée, de telle sorte que la sortie du bruit source soit déterminé dans un espace fixe.
\item le \textbf{composant de conditionnement}, qui permet d'augmenter ou diminuer le taux d'entropie reçu. L'algorithme de conditionnement doit être un algorithme cryptographique approuvé.
\item une \textbf{batterie de tests}, partie également intégrante du système. Des tests sont réalisés pour déterminer l'état de santé du générateur aléatoire, permettant de s'assurer que la source d'entropie fonctionne comme attendu. On considère 3 catégories de tests : 
	\begin{itemize}
	\item Les tests au démarrage sur tous les composants de la source
	\item Les tests lancés de façon continue sur le bruit généré par la source
	\item Les tests sur demande (qui peuvent prendre du temps)
	\end{itemize}
	L'objectif principal de ces tests est d'être capable d'identifier rapidement des échecs de génération d'entropie, ceci avec une forte probabilité. Il est donc important de déterminer une bonne stratégie de détermination d'échec pour chacun de ces tests.\\
\end{itemize}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node (source) {\textbf{Source d'entropie}};
\node (bruit) [below of=source,yshift=1cm,xshift=0.5cm] {\textbf{Bruit}};
\node (donnees) [io,below of=bruit,yshift=1cm,xshift=0.5cm,pattern=dots,pattern color=orange] {Données};
\node (digit) [process, right of=donnees, xshift=4cm] {Digitalisation};
\node (cond) [process, below of=digit,text width=3cm,yshift=-0.5cm] {Conditionnement (optionnel)};
\node (bat) [process, right of=cond, xshift=4cm] {Batterie de tests}; 
\node (dec) [decision, below of=cond,yshift=-0.5cm] {Sortie}; 
\node (appli) [process, below of=dec, yshift=-1cm] {Application};

\begin{pgfonlayer}{background}
\node[punkt, fit=(donnees)(digit)(cond)(bat)(dec)(bruit)(source), fill=yellow!5] (groupclient) {};
\end{pgfonlayer}

\begin{pgfonlayer}{background}
\node[punkt, fit=(donnees)(digit)(bruit), fill=yellow!20] (groupclient) {};
\end{pgfonlayer}

\draw [arrow] (donnees) -- (digit);
\draw [arrow] (digit) -- node[anchor=east] {out1}(cond);
\draw [arrow] (cond) --  node[anchor=east] {out2} (dec);
\draw [arrow] (digit) -| node[anchor=south] {out1} (bat);
\draw [arrow] (cond) -- node[anchor=south] {out2} (bat);
\draw [arrow] (bat) |- node[anchor=north] {true/false} (dec);
\draw [arrow] (dec) -- node[anchor=east] {output/error}  (appli);
\end{tikzpicture}
\end{center}
\caption{Composants d'une source d'entropie. \texttt{out1} est une chaîne binaire de taille quelconque et \texttt{out2} est une chaîne binaire conditionnée de taille fixe. }
\end{figure}

\paragraph{Modèle conceptuel.\\}
Suivant ces sections précédentes, on peut déterminer 3 interfaces conceptuelle :
\begin{itemize}
\item \texttt{getEntropy} qui retourne 
	\begin{itemize}
	\item \texttt{entropy\_bitstring}, une chaîne de bits de l'entropie demandée
	\item \texttt{assessed\_entropy}, entier indiquant le nombre de bits d'entropie de \texttt{entropy\_bitstring}
	\item \texttt{status}, booléen renvoyant \texttt{true} si la requête est satisfaite, \texttt{false} sinon.\\
	\end{itemize}
\item \texttt{getNoise}	 qui prend en entrée : 
	\begin{itemize}
	\item \texttt{number\_of\_sample\_requested}, entier indiquant le nombre d'éléments demandés en retour à la source de bruit
	\end{itemize}
et en sortie : 
	\begin{itemize}
	\item \texttt{noise\_source\_data}, la séquences d'éléments demandée, ayant la taille \texttt{number\_of\_sample\_requested}.
	\item \texttt{status}, booléen renvoyant \texttt{true} si la requête est satisfaite, \texttt{false} sinon.\\
	\end{itemize}
\item \texttt{HealthTest}, élément test de la batterie de tests, qui prend en entrée :
	\begin{itemize}
	\item \texttt{type\_of\_test\_requested}, chaine de bits déterminant le type de tests que l'on souhaite effectuer (peut différer suivant le type de source)
	\end{itemize}
et en sortie : 
	\begin{itemize}
	\item \texttt{pass-fail\_flag}, booléen qui renvoie \texttt{true} si la source d'entropie a réussi le test, \texttt{faux} sinon.
	\end{itemize}	
\end{itemize}


\subsection{Forces et faiblesses des différents PRNG}

	Nos machines utilise ce qu'on appel des PRNG (Pseudo Random Number Generator), 
	ce sont des algorithmes qui génèrent une séquence de nombre s'apparentant
	à de l'aléatoire. En réalité rien est aléatoire car tout est déterminé par
	des valeurs initiales (État du PRNG) et des contextes d'utilisation.\\
	
	Un bon PRNG se doit d'avoir une très forte entropie (proche de un), afin
	d'éviter de délivrer de l'information.

	Comme l'entropie est fourni majoritairement (si ce n'est totalement) par 
	l'OS, il est donc nécessaire de détailler les PRNG les plus utilisés
	(Surtout par les systèmes Linux et BSD - qui sont les ceux qui générent le
	plus de certificats SSL).\\

	Nous nous basons sur la RFC 4086 \cite{rfc4086}: 
	Randomness requirements for security
	pour le choix des PRNG selon les différents	systèmes.

	\subsubsection{/dev/urandom et /dev/random sous Linux}
	
		Sous Linux, un pool est initialisé avec 512 octets, auquel on ajoute
		le temps émis par un évènement et son état parmis : 
		\begin{itemize}
			\item Les interruptions clavier - heure et code d'interruption
			\item Les interruptions de disques - heure de lecture ou écriture
			\item Les mouvements de souris - heure et position\\
		\end{itemize}
	
		Quand des octets aléatoires sont demandés, la pool est haché avec SHA-1 
		(20 octets). S’il est demandé plus que 20 octets, le haché est mélangé 
		dans la pool pour rehacher la pool ensuite etc. À chaque fois que l’on 
		prend des octets dans la pool, l’entropie estimée est décrémentée.\\

		Pour assurer un niveau minimum d’entropie au démarrage, la pool est 
		écrite dans un fichier à l’extinction de la machine.\\

		/dev/urandom fonctionne selon le même principe sauf qu’il n’attend pas 
		qu’il y ait assez d’entropie pour donner de l’aléatoire. Il convient 
		pour une génération de clefs de session.\\

		Pour générer des clefs cryptographiques de longue durée, il est 
		recommandé d’utiliser /dev/random pour assurer un niveau minimum 
		d’entropie.\\
		
		En effet, sur un serveur sans souris ni clavier, définir l'entropie avec
		/dev/urandom est très risqué. On recommande donc l'utilisation de 
		/dev/random lors de l'audit OpenSSL sur les versions Linux.\\

		/dev/random utilise une pool d’entropie de 4096 bits (512 octets) génère 
		de l’aléa et s’arrête lorsqu’il n’y a plus assez d’entropie et attend 
		que la pool se remplisse à nouveau.\\
		
		Si vous souhaitez connaître l'entropie disponible, la commande est : \\
		cat /proc/sys/kernel/random/entropy\_avail\\

		Désormais, la taille de la pool est hardcodée dans le noyau Linux 
		(/drivers/char/random.c:275)\\
		
		Linux offre également la possibilité de récupérer de l’aléa depuis un 
		RNG matériel avec la fonction get\_random\_bytes\_arch
		\cite{archlinuxRNG}\\
	
		Un patch est également disponible afin de générer de l'aléa avec un 
		débit de 100kB/s \cite{mueller2013rng}. 
		L'entropie est récupérée par le CPU timing jitter.\\
		
		En conclusion, /dev/random doit être utilisé pour une haute qualité
		d'entropie (i.e. haute sécurité de chiffrement, one-time pad).\\
		Tandis que /dev/urandom doit être utilisé pour des applications non
		sensibles à des attaques cryptographiques (i.e. jeu en temps réel),
		car elle génère plus d'entropie que /dev/random sur un temps donné, 
		mais s'arrêtera même si il n'a pas récolté suffisamment d'entropie. 
	

	\subsection{/dev/random sous FreeBSD et /dev/arandom sous OpenBSD}
	
		Il faut faire attention au faux ami, le /dev/random du FreeBSD n'est pas 
		le même que celui de Linux.
		En fait, il est semblable au /dev/urandom de Linux, et est donc tout 
		autant proscrit lors de notre audit.\\
		
		Même principe avec le /dev/arandom de OpenBSD, qui a également une 
		entropie faible pour du chiffrement cryptographique sûr. Il se base
		en fait sur un algorithme modifié du RC4 nommé ARC4 (Alleged RC4) pour 
		générer des données aléatoires.\\
		Pour rappel, RC4 était un projet commercial de la RSA Security, et un 
		hacker anonyme a publié un code identique, devenu légitime, identifié par
		ARC4.\\
		De nos jours, il est fortement conseillé de ne plus utiliser RC4 car le 
		flux de données aléatoire n’est pas vraiment aléatoire et il existe des 
		attaques qui prédisent la sortie de l’algorithme (Attaque de Fluhrer, 
		Mantin et Shamir) \cite{fmsrc42009}.\\
		Sur plusieurs de nos sources (plus anciennes), il est recommandé
		d'utiliser /dev/arandom pour sa rapidité (71 Mb/s) et sa bonne source
		d'entropie. Ce n'est plus vraiment le cas aujourd'hui.\\
		
		
		
	
	\subsection{CryptGenRandom sous Windows}
	
		Du coté de Microsoft, il recommande aux utilisateurs de Windows 
		d’utiliser CryptGenRandom, qui est un appel système de génération d’un 
		nombre pseudo-aléatoire. La génération est réalisée par une librairie 
		cryptographique (Cryptographic service provider library). Celui ci gère 
		un pointeur vers un buffer en lui fournissant de l’entropie afin de 
		générer un nombre pseudo aléatoire en retour avec en plus, le nombre 
		d’octet d’aléatoire désiré.\\

		\lstset{language=Java}
		\begin{lstlisting}
		BOOL WINAPI CryptGenRandom(
			_In_     HCRYPTPROV hProv,
			_In_     DWORD dwLen,
			_Inout_  BYTE *pbBuffer
		);
		\end{lstlisting}
	
		Le service provider sauvegarde une variable d’état d’un sel pour chaque 
		utilisateur. Lorsque CryptGenRandom est appelé, celui ci est combiné 
		avec un nombre aléatoire généré par la librairie en plus de différentes 
		données systèmes et utilisateurs telles que : \\
		\begin{itemize}
		\item l’ID du processus
		\item l'ID du thread
		\item l'horloge système
		\item l'heure système
		\item l'état de la mémoire
		\item l’espace de disque disponible du cluster
		\item le haché du block d'environnement mémoire de l’utilisateur\\
		\end{itemize} 
		
		Le tout est envoyé à la fonction de hachage SHA-1 et le nombre en sortie 
		est utiliser comme sel pour une clef RC4. \\
		
		Cette clef est enfin utilisé pour produire des données pseudo aléatoire 
		et mettre à jour la variable d’état du sel de l’utilisateur. 

	
	
	\subsection{Autres systèmes}
	
		Nous avons également d'autres RNG comme srandom, prandom ou
		encore wrandom \cite{miros2013}\\
		
		/dev/srandom est simple et lent, il n'est pas recommandé de l'utilisé.\\
	
		Certains systèmes ne disposant pas de /dev/*random, il est alors possible
		d'utiliser l'EGD (Entropy Gathering Daemon) \cite{egdsf.net}.\\
		
		Il faut pour cela utiliser les fonctions OpenSSL RAND\_egd, 
		RAND\_egd\_bytes et RAND\_query\_egd\_bytes. \\
		
		L'EGD est également utilisé par GPG, et peut être utilisé comme seed.




\subsection{Standards}
\subsubsection{RFC 4086}
\subsubsubsection{Sous Linux}
Suivant la RFC 4086 \nocite{rfc4086} intitulée \textit{Randomness requirements for security} \nocite{rfc4086}, 
Il existe plusieurs niveaux de récupération d'aléatoire sous linux  :
\begin{itemize}
\item Point primaire (\textit{Primary pool}) :\\
512o (128 mots de 4o) + ajout d’entropie
\item Point secondaire (\textit{Secondary pool}) :\\
128o pour générer le fichier \texttt{/dev/random}. Un autre point secondaire existe : \texttt{/dev/urandom}\\
\end{itemize}

L'entropie est récupérée par exemple lorsqu'un événement apparaît (telle qu'une interruption du disque dur), la date et l'heure de l'événement est récupéré et XORée dans le \textit{pool}, puis  est "mélangée" avec une primitive polynomiale possédant un degré de 128. Le \textit{pool} devient ensuite une boucle où de nouvelles données sont XORées ("mélangées" encore par la primitive polynomiale) tout le long du \textit{pool}.\\


A chaque appel qui rajoute de l'entropie dans le \textit{pool}, celui-ci calcule une estimation de la probabilité d'une réelle entropie des données. Le pool contient alors l'accumulation des estimations de l'entropie totale contenue dans le pool.\\


Les sources d'entropie sont les suivantes :
\begin{itemize}
\item Interruption Clavier  
\item Interruption des complétions du disque
\item Mouvements de la souris
\end{itemize}

Quand des octets aléatoires sont demandés, la \textit{pool} est haché avec SHA-1 (20 octets). Si plus de 20 octets  est demandé plus que 20 octets, le haché est mélangé dans la pool pour rehacher la pool ensuite etc. À chaque fois que l’on prend des octets dans la pool, l’entropie estimée est décrémentée. Pour assurer un niveau minimum d'entropie au démarrage, la \textit{pool} est écrite dans un fichier à l'extinction de la machine.\\

\texttt{/dev/urandom} fonctionne selon le même principe sauf qu'il n'attend pas qu'il y ait assez d'entropie pour donner de l'aléatoire. Il convient pour une génération de clefs de session. Pour générer des clefs cryptographiques de longue durée, il est recommandé d'utiliser \texttt{/dev/random} pour assurer un niveau minimum d'entropie.\\

\subsubsubsection{Sous Windows}
Du coté de Microsoft, il est recommandé aux utilisateurs d'utiliser \texttt{CryptGenRandom}, qui est un appel système de génération d'un nombre pseudo-aléatoire. La génération est réalisée par une librairie cryptographique (\textit{Cryptographic service provider library}). Celle-ci gère un pointeur vers un \textit{buffer} en lui fournissant de l'entropie afin de générer un nombre pseudo aléatoire en retour avec en plus, le nombre d'octets d'aléatoires désirés.

\begin{verbatim}
BOOL WINAPI CryptGenRandom(
  _In_     HCRYPTPROV hProv,
  _In_     DWORD dwLen,
  _Inout_  BYTE *pbBuffer
);
\end{verbatim}


Le service \textit{provider} sauvegarde une variable d'état d'un sel pour chaque utilisateur. Lorsque \texttt{CryptGenRandom} est appelé, celui-ci est combiné avec un nombre aléatoire généré par la librairie en plus de différentes données systèmes mais aussi de l'utilisateur tels que l'ID du processus  du \textit{thread}, l'horloge système, l'heure système, l'état de la mémoire, l'espace de disque disponible du \textit{cluster} et le haché du block d'environnement mémoire de l'utilisateur. \\

Le tout est envoyé à la fonction de hachage SHA-1 et le nombre en sortie est utilisé comme sel de clef RC4.  Cette clef est enfin utilisée pour produire des données pseudo-aléatoires et mettre à jour la variable d'état du sel de l'utilisateur. 

\subsubsubsection{OpenBSD}
Dans OpenBSD, on trouve des sources d'aléatoire supplémentaires par rapport à Linux. On trouve notamment \texttt{/dev/arandom} qui génère de l'aléatoire selon une version leakée de RC4 : \texttt{ARC4} (Alleged RC4). Pour rappel, RC4 était un projet commercial de RSA Security et un hacker anonyme a publié un code qui faisait la même chose, code légitime identifié par ARC4. De nos jours, il est fortement conseillé de ne plus utiliser RC4 car le flux de données aléatoires n'est pas vraiment aléatoire et il existe des attaques qui prédisent la sortie de l'algorithme (Attaque de Fluhrer, Mantin et Shamir) \nocite{Fluhrer01weaknessesin}.



\section{Audits}
	\subsection{Audit 1 : Le cas Debian 4.0 et OpenSSL 0.9.8}
	\subsubsection{Norme visée}
	\subsubsection{Faille}
		\subsubsubsection{Description}
		Le 13 Mai 2008, Luciano Bello découvert une faille critique du 
		paquet d'OpenSSL sur les systèmes Debian
		\cite{faille2008linux.org}. Un mainteneur Debian 	
		souhaitant corriger quelques bugs aurait malencontreusement 	
		supprimé une grosse source d'entropie lors de la génération des 
		clés. \\
		Il ne restait plus que le PID comme source d'entropie!\\
		Comme celui-ci ne pouvait dépasser 32.768 (qui le PID maximal
		atteignable), l'espace des clés a été restreint à 264.148 clés
		distinctes.\\
		
		Analysons plus en détail cette faille. Elle se situe au niveau de 
		la fonction \textbf{md\_rand.c}.
		La ligne \textbf{MD\_Update(\&m, buf, j);} a été commentée.
		La conséquence est le blocage de la graine (seed) que l'on 
		passe ensuite au PRNG.\\
	
		Cette ligne a été commentée par erreur en voulant corriger un
		avertissement soulevé par le compilateur Valgrind sur une valeur
		non initialisé.\\
	
		Le 14 Mai 2008, Steinar H. Gunderson démontre simplement comment
		en connaissant le secret $k$ d'une signature, on peut retrouver
		la clé privée d'un certificat immédiatement \cite{gunderson2008}.\\
	
		Ce secret k étant généré avec un PRNG prévisible, on peut stocker
		deux signatures utilisant le même $k$, où le prédire directement.\\
	
		Une signature DSA consiste en deux nombres $r$ et $s$ tels que :\\
		$r = (g^k [p]) [q]$\\
		$s = (k^{-1} * (H(m) + x * r)) [q]$\\
	
		La clé publique = $(p, q, g)$.\\
		Le message en clair = $m$, et $H(m)$ est le fingerprint de $m$ connu.\\
	
		Attaque \no 1 : En connaissant $k$	\\
		$s * k [q] = (H(m) + x*r) [q]$\\
		$\iff (s * k - H(m)) [q] = x*r [q]$\\
		$\iff ((s*k - H(m))*r^{-1})[q] = x$\\
		$\iff (s*k - H(m))*r^{-1} = x$\\

		Attaque \no 2 : Deux messages possèdent le même $k$\\
		$s_1 = (k^{-1} (H(m_1) + x*r)) [q]$\\
		$s_2 = (k^{-1} (H(m_2) + x*r)) [q]$\\
		$\iff s_1 - s_2 = (k^{-1} (H(m_1) - H(m_2)) [q]$\\
		$\iff (s_1 - s_2)*(H(m_1) - H(m_2))^{-1} = k^{-1} [q]$\\
		$\iff$ On connaît $k \implies$ Attaque 1\\

		Pour savoir si une clé SSL, SSH, DNSSEC ou OpenVPN est affectée, 
		plusieurs détecteur de données \cite{dowkd.pl} 
		\cite{openssl-blacklist} de clés faibles sont 
		fournis par l'équipe Security de Debian, en même temps que
		l'avertissement de sécurité \cite{debian2008bug}.\\ 

		\subsubsubsection{Tests}

		Nous avons décidé de tester le nombre de certificats vulnérables 
		causés 	par le bug OpenSSL de Debian (qui reste le plus populaire), et
		connaissant la blacklist des clés privés. \\
	
		Les résultats nous montrent que sur 500.000 certificats récupérés, au moins
		\footnote{Le logiciel ne prend pas en compte les clés $\leq$ à 512 bits et 
		celles $\geq$ à 4096 bits, et ne prend en compte que les certificats RSA} 
		769 sont vulnérables.\\
		
		Vous pouvez trouver nos scripts parcourant un fichier contenant un 
		certificat sur chaque ligne, ou un dossier contenant des certificats sous 
		forme de fichiers PEM et nos résultats, dans le dossier consacré à l'audit des clés
		cryptographiques.\\
		
		Le format de nos résultats est : \\
		
		\textbf{COMPROMISED:} \textit{<haché\_du\_certificat>} \textit{<nom
		\_fichier\_corrompu (sous forme d'adresse IP)}\\
		
		Évidemment, nous ne mettons pas ces résultats sur le net puisqu'il indique 
		très clairement les adresses IP contenant le certificat friable, et sa clé
		privée (que l'on peut facilement retrouvé parmi la courte blacklist).\\
		
		Pour information, parmi les entreprises vulnérables nous trouvons les géants
		IBM et CISCO.
	
	\subsubsection{Implémentation}
		
		\paragraph{Version OpenSSL.\\}
		
		\paragraph{Fonction.\\}
		La fonction liée à cette norme est accessible sous le paquetage \texttt{bla/bla/bla}, dont les composantes principales sont listées en \textit{listing} \ref{codeAleatoire}.
		
		
		\begin{lstlisting}[style=customc,caption=codeAleatoire.c, label=codeAleatoire]
#include <stdio.h>
#define N 10
/* Block
 * comment */
 
int main()
{
    int i;
 
    // Line comment.
    puts("Hello world!");
 
    for (i = 0; i < N; i++)
    {
        puts("LaTeX is also great for programmers!");
    }
 
    return 0;
}
		\end{lstlisting}
		
		
		
		\paragraph{Audit.\\}

	\subsection{Audit 2 : Le cas LinuxMintDebianEdition sous Android}
	\subsubsection{Norme visée}
	\subsubsection{Faille}
	
		Récemment, en Août 2013 précisément, un patch de sécurité pour les 
		systèmes Android utilisant la version LinuxMintDebianEdition/OpenSSL, 
		dévoile une réparation du générateur de nombres pseudo-aléatoire (PRNG) 
		qui ne donnait pas suffisamment d'entropie
		\cite{alex2013android} \cite{bochum2013randomly}. \\
		
		Le patch indique que le PRNG de cette version d'OpenSSL utilise dorénavant 
		une combinaison de données plus ou moins prévisibles associées à 
		l'entropie générées par /dev/urandom. \\
		Mais sachant que le PRNG d'OpenSSL utilise lui-même /dev/urandom, on a du 
		mal à comprendre pourquoi en rajouter davantage.\\
	
		Eric Wong et Martin Boßlet apporte la solution sur leur site
		\cite{boblet2013android}, l'erreur 
		provient d'un bug "à la Debian", une simple ligne diffère de la version 
		officielle d'OpenSSL (utilisant SecureRandom) à celle de OpenSSL::Random 
		ce situant dans la fonction ssleay\_rand\_bytes. \\
	
		La cause est là même que celle de Debian, un patch de sécurité atteint la 
		source d'entropie du PRNG. Alors que tout semblait être rentré dans 
		l'ordre, un résidu de cette erreur reste dans cette version. Les 
		développeurs d'OpenSSL assure que ça n'a pas d'impact (ou alors très peu) 
		sur la sécurité globale. 
		Mais à cause de la mémoire non initialisé des systèmes Android, la source 
		d'entropie ne nous permet pas de générer des nombres non-prédictibles. \\
	
		La conséquence n'est pas aussi lourde que celle de Debian, tout d'abord 
		parce que le système Android est rarement utilisé pour du 
		chiffrement de données sensible, et une attaque par prédiction bien que
		plus rapide qu'une attaque par brute-force, reste infaisable. 
		Mais l'erreur est quand même là. \\

	
	\subsubsection{Implémentation}
		
		\paragraph{Version OpenSSL.\\}
		
		\paragraph{Fonction.\\}
		La fonction liée à cette norme est accessible sous le paquetage \texttt{bla/bla/bla}, dont les composantes principales sont listées en \textit{listing} \ref{codeAleatoire}.
		
		
		\begin{lstlisting}[style=customc,caption=codeAleatoire.c, label=codeAleatoire]
#include <stdio.h>
#define N 10
/* Block
 * comment */
 
int main()
{
    int i;
 
    // Line comment.
    puts("Hello world!");
 
    for (i = 0; i < N; i++)
    {
        puts("LaTeX is also great for programmers!");
    }
 
    return 0;
}
		\end{lstlisting}
		
		
		
		\paragraph{Audit.\\}

	\subsection{Audit 3 : Le cas LinuxMintDebianEdition sous Android}
	\subsubsection{Norme visée}
	\subsubsection{Faille}
	
	C'est le syndrome OpenSSH de Debian qui frappe une nouvelle fois.\\
	Du fait d'une parenthèse mal placée dans le code du fichier 
	/src/sys/kern/subr\_cprng.c, il s'avère que le générateur pseudo-aléatoire 
	de NetBSD 6.0 est bien moins solide que ce qui était attendu.\\
	Sa sortie est prévisible et il faut d'urgence changer les clés SSH qui ont été générées avec ce noyau.\\
	
	\subsubsection{Implémentation}
		
		\paragraph{Version OpenSSL.\\}
		
		\paragraph{Fonction.\\}
		La fonction liée à cette norme est accessible sous le paquetage \texttt{bla/bla/bla}, dont les composantes principales sont listées en \textit{listing} \ref{codeAleatoire}.
		
		
		\begin{lstlisting}[style=customc,caption=codeAleatoire.c, label=codeAleatoire]
#include <stdio.h>
#define N 10
/* Block
 * comment */
 
int main()
{
    int i;
 
    // Line comment.
    puts("Hello world!");
 
    for (i = 0; i < N; i++)
    {
        puts("LaTeX is also great for programmers!");
    }
 
    return 0;
}
		\end{lstlisting}
		
		
		
		\paragraph{Audit.\\}



\section{Recommandations sur la conception}
Le NIST propose des recommandations à plusieurs niveaux concernant la conception de la source d'entropie. Nous n'en reporterons ici que les recommandations génériques. Les éléments ci-dessous sont basés 

\subsection{Modélisation et validation}
La source d'entropie doit suivre les exigences suivantes 
\begin{enumerate}
\item Le développeur doit documenter complètement la modélisation de la source d'entropie, incluant toutes les interactions entre les composants. De ce fait, la documentation doit pouvoir justifier en quoi la source d'entropie est de confiance. 
\item Il doit définir de façon précise les limites conceptuelles de sécurité de la source d'entropie, qui doivent elles mêmes être équivalentes à un module cryptographique délimitant un périmètre de sécurité (cf. \textit{Cryptographic module boundary} du FIPS 140).
\item Le développeur doit définir le champ des conditions optimales de fonctionnement du générateur d'entropie.
\item La source source d'entropie doit être possiblement validée suivant les recommandations du FIPS 140, ainsi que les tests s'y référant.
\item Le comportement du bruit de la source doit être documenté, validant en quoi le taux d'entropie ne fluctue pas lors d'une utilisation normale.
\item Dès lors qu'un test de validation n'est pas réussi, la source d'entropie doit immédiatement cesser d'envoyer des données de sortie, et doit notifier à l'application l'erreur rencontrée.\\

Enfin, une recommandation optionnelle : 
\item La source d'entropie doit contenir différent types de bruits pour améliorer le comportement global de la source, et prévenir des tentatives de contrôle externe. Chaque bruit doit vérifier les spécifications du 3.1. 
\end{enumerate}

\subsection{Source d'entropie absolue}
Certains générateurs de bits aléatoire demandent une source d'entropie absolue, à savoir qu'elle approxime une sortie qui est uniformément distribuée et indépendante des autres sorties. 
\begin{enumerate}
\item La chaine de bit générée doit fournir au moins $(1-\epsilon)n$ bits d'entropie, où : 
	\begin{itemize}
	\item $n$ est la taille de chaque sortie
	\item $\epsilon$ tel que : $0\leqslant \epsilon \leqslant 2^{-64}$
	\end{itemize}
\end{enumerate}

\subsection{Bruit de la source}
Le bruit fournit par la source doit suivre les recommandations suivantes :
\begin{enumerate}
\item Le bruit doit avoir un comportement probabiliste et ne doit en aucun cas être définissable par quelconque algorithme ou règle.
\item Le développeur doit pouvoir documenter l'opération sur le fonctionnement du bruit de la source, en montrant en quoi le choix de ce bruit fournit une sortie d'entropie acceptable. Ceci comprend le référencement d'articles de recherche et autre littérature pertinente.
\item Le bruit de la source doit pouvoir être testable, de telle sorte que l'on puisse s'assurer qu'il effectue l'opération attendue. Il doit donc être possible de récupérer des données sur la source de bruit sur lesquels on puisse lancer la batterie de tests. La récupération des données sur la source de bruit ne doit en aucun cas altérer le comportement du bruit, ou de la sortie.
\item Toute défaillance du bruit doit être rapidement détectable. Les méthodes de détection doivent être documentées.
\item La documentation de la source du bruit doit également décrire sous quelles conditions le bruit est connu pour mal fonctionner. Ceci consiste ainsi à répertorier les environnements dans lesquels la source peut fonctionner correctement. 
\item La source de bruit doit être protégée au maximum contre toute attaque/tentative de conditionnement ou simple connaissance de fonctionnement de la part d'un adversaire. 
\end{enumerate}

\subsection{Composant de conditionnement}
Le composant de conditionnement doit suivre les recommandations suivantes :
\begin{enumerate}
\item Le développeur doit documenter si la source d'entropie nécessite ou non un conditionnement. 
\item La méthode de conditionnement doit être décrite et argumentée. Elle doit en effet expliciter en quoi elle permet de diminuer l'alignement d'une source de bruit, ou en quoi la sortie créée correspond à l'entropie attendue
\item La méthode de conditionnement doit pouvoir être validée par des tests
\item Le développeur doit pouvoir estimer l'alignement en sortie de conditionnement. 
\item Le développeur doit prévoir une documentation expliquant le comportement de la méthode de conditionnement en cas de variation de comportement de la part de la source de bruit.
\end{enumerate}

\subsection{Batterie de tests}
Globalement, les tests doivent suivre les recommandations suivantes :
\begin{enumerate}
\item Les tests doivent être effectués au démarrage puis de façon continuelle pour s'assurer que les composants du générateur d'entropie fonctionnent correctement.
\item Tous les tests doivent être documentés, en particulier sur les conditions sous lesquels ils doivent être exécutés, les résultats attendus pour chacun de ceux-ci, et une explication rationnelle indiquant en quoi chaque test est approprié pour la détection de dysfonctionnement de la part de la source d'entropie. 
\end{enumerate}

\subsubsection{Tests sur le bruit}
Les tests sur le bruit sont pour la plupart du temps dépendants de la technologie utilisée. Dans la majorité des cas, il faut tester via des procédures traditionnelles de tests (type test monobit, test du $\chi_2$, et tests d'exécution) si celui-ci est bien non biaisé et produit des données indépendantes.
\begin{enumerate}
\item Au minimum, des tests continus doivent être implémentés, et ceci de façon indépendante. Le développeur doit de plus documenter toutes les sources de défaillance.
\item Les tests sont implémentés sur les données binaires récupérées via le bruit source.
\item La source de bruit doit être testé dans son ensemble (suivant la variation du bruit).
\item Le bruit généré durant la démarrage ayant passé avec succès les tests de démarrage peut être utilisé pour produire de l'entropie.
\item Lorsqu'un test est échoué, le générateur doit en être notifié.\\

Optionnel : 
\item Une étude peut être requise sur les bords du bruit bruit généré, dans les cas ou le comportement du générateur est altéré.
\end{enumerate}


\subsubsection{Tests sur le conditionnement}
Le rôle du conditionnement est de réduire l'alignement  présent chez certaines sources d'entropie afin de s'assurer que l'entropie est construite à un taux acceptable. Les recommandations sont les suivantes :
\begin{enumerate}
\item Les composants de conditionnements doivent être testés dès le démarrage, afin d'être certain que le générateur fonctionne comme prévu
\item Le développeur doit documenter les tests implémentés et inclure les conditions d'échecs pour chacun d'entre eux.
\end{enumerate}



\section{Tests effectifs sur l'entropie fournie par les sources d'entropie}

\subsection{Déterminer si les données sont IID}

\paragraph{Définition.\\}
On dit que des variables sont \textbf{IID} (indépendantes et identiquement distribuées) si elle suivent toute la même loi de probabilité et si elles sont mutuellement indépendantes. \\

Les tests suivants ont été conçus pour montrer si les données en sortie du bruit et/ou en sortie du conditionnement sont bien IID, ceci en effectuant des tests sur la distribution des données. Le but est de vérifier l'hypothèse $H_0$. Pour la vérifier, nous allons considérer ici deux types de tests : 
\begin{itemize}
\item Des tests de répartition aléatoire sur l'ensemble
\item Des tests statistiques\\
\end{itemize}

Si un des tests est passé, alors on passe au suivant. La défaillance d'un seul des tests impliquera le caractère non IID des données. 


\subsubsection{Tests sur l'indépendance et la stabilité}
Nous travaillons sur le test statistique bilatéral suivant : 
\begin{itemize}
\item l'hypothèse $H_0$ : "Les données sont IID". 
\item l'hypothèse $H_1$ : "Les données ne sont pas IID". \\

\end{itemize}


Suivant un jeu de données $(|donnees|=n)$, on divise celui-ci en 10 sous ensemble de tailles égales ($\frac{N}{10}$). On effectue enfin nos tests sur chacune de ces données. La stratégie de test est effectuée comme suit : 
\begin{enumerate}
\item On calcule tout d'abord différents scores statistiques parmi les suivants :
	\begin{itemize}
	\item Score de compression, un score par sous ensemble de données
	\item Score \textit{Over/Under Runs}, deux scores par sous ensemble
	\item Score excursion, un score par sous ensemble
	\item Score \textit{Runs} directionnel, trois scores par sous ensemble
	\item Score de covariance, un score par sous ensemble 
	\item Score de collision, trois scores par sous ensemble\\
	\end{itemize}
	
\item Pour chaque calcul de score : 
	\begin{enumerate}
	\item On stocke pour chaque type de score les résultats dans un vecteur de $J$ scores
	\item On répète les étapes suivantes 1000 fois :
		\begin{enumerate}
		\item On permute les sous ensembles précédents en utilisant un générateur pseudo aléatoire, suivant l'algorithme de permutation  \textit{Fisher–Yates shuffle}. 
		\item On calcule les nouveaux scores suivant cette nouvelle organisation de sous-ensembles
		\item On récupère ce vecteur de $J$ scores
		\end{enumerate}
	\item On classifie les scores de 2a) en le comparant avec tous les scores liés permutés. Par exemple, si le score des données originelles est plus grand que tous ceux des permutations, alors ce premier a le score de 1000, et les répertoires permutés on un score inférieur à 1000. Il est possible que les données permutées aient le même score. Lorsque le score originel est le même que certains de scores des données permutées, on considère le score en récupérant celui le plus proche de la médiane. \\
	
Plus généralement, étant donné : 
		\begin{itemize}
		\item Un score $S$
		\item Une liste de scores des données permutées $L$
		\end{itemize}
	On détermine le \textbf{rang de $S$} tel que : 	
	
	$$
	Rang(S) = \left\{
		\begin{array}{llllll}
		max(j) & \text{tel que} & L[j] \leqslant S,& si& L[500]>S & (1)\\
		500 & &si& L[500]=S & (2)\\ 
		min(j) & \text{tel que} & L[j] \geqslant S,& si& L[500]<S & (3)\\
		\end{array}			
	\right.
	$$ 
	\newline	
	
		\begin{enumerate}	
		\item Exemple cas (1) :
			\begin{itemize}
			\item Soit $S=20$ et $L[500]=22$. On est dans le cas (1). On va chercher le $max(j)$ tel que $ L[j] \leqslant S$.
			\item On a $L[299]=19$, $L[300]=20$, $L[301]=20$, $L[302]=22$.
			\item On retourne au score $301$, ainsi $Rang(S)=301$.\\
			\end{itemize}
			
		\item Exemple cas (3) :
			\begin{enumerate}
			\item Soit $S=20$ et $L[500]=18$. On est dans le cas (3). On va chercher le $max(j)$ tel que $ L[j] \geqslant S$.
			\item On a $L[599]=19$, $L[600]=20$, $L[601]=20$.
			\item On retourne au score $600$, ainsi $Rang(S)=600$.\\
			\end{enumerate}
			
		\end{enumerate}
	\end{enumerate}
	
\item Le rang alors obtenu est considéré comme une \textit{p-value} pour un test bilatéral. Pour rappel, une \textit{p-value} est la probabilité d'obtenir la même valeur de test si l'hypothèse nulle est vraie. Ainsi, on compte pour chacun des 6 tests un ensemble de $10*J$ \textit{p-values}.\\

\item On gère enfin les \textit{p-values} de la façon suivante : 
	\begin{enumerate}
	\item Tous les rangs compris entre 50 et 950 sont relevés. Ces événements ont une probabilité d'arriver de 10\% au total. 
	\item Si le nombre de rangs relevés est supérieur ou égal à 8, on considère le test comme échoué.
		\begin{enumerate}
		\item Si le test est effectué sur la source du bruit, alors celle-ci n'est pas considérée comme IID
		\item Si le test est effectué sur le conditionnement, alors  la source d'entropie n'est pas validée.
		\end{enumerate}
	\end{enumerate}
\end{enumerate}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node 	(titre) 		[]{\textbf{Test $t$}};
\node	(donnees) 	[process,below of=titre,yshift=1cm, xshift=6cm]	{Données (taille $n$)};
\node	(n101) 		[process,below of=donnees,xshift=-3cm]	{$\frac{n}{10}$};
\node	(n102) 		[process,below of=donnees,xshift=3cm]	{$...$};
\node	(n1010) 		[process,below of=donnees,xshift=9cm]	{$\frac{n}{10}$};
\node	(permut) 	[process,below of=n101,xshift=2cm]	{$permutation$};
\node	(ini) 		[process,below of=n101,xshift=-2cm]	{$score_t^{ini}$};
\node	(score) 		[process,below of=permut]	{$score_t[j]$};	
\node 	(dec) 		[decision, below of=score,yshift=-0.4cm] {$j<1000$}; 
\node 	(rangs) 		[process, below of=dec,yshift=-0.4cm] {$rangs[j]$}; 
\node 	(dec2) 		[decision, below of=rangs,yshift=-0.4cm] {$Out>8$}; 
\node 	(fail) 		[below of=dec2, yshift=-0.4cm] {Test échoué}; 
\node 	(reussi) 	[right of=dec2,xshift=3cm] {Test réussi}; 

\begin{pgfonlayer}{background}
\node[punkt, fit=(titre)(donnees)(n101)(n102)(n1010)(permut)(ini)(score)(dec)(rangs)(dec2)(fail)(reussi), fill=yellow!5] (groupclient) {};
\end{pgfonlayer}

\draw	[arrow]		(donnees)	-|		(n101);
\draw	[arrow]		(donnees)	-|		(n102);
\draw	[arrow]		(donnees)	-|		(n1010);
\draw	[arrow]		(n101) 	-|	node[anchor=west] {$j=0$}	(permut);
\draw	[arrow]		(n101)	-|		(ini);
\draw	[arrow]		(permut)	--	node[anchor=west] {$j++$}	(score);
\draw	[arrow]		(score)	--	(dec);
\draw 	[arrow]		(dec) --++ (+3,0) node [near start,anchor=south] {vrai} |- (permut);
\draw	[arrow]		(dec)	-- node[near start,anchor=west] {faux}	(rangs);
\draw	[arrow]		(ini)	|-	(rangs);
\draw	[arrow]		(rangs)	--	(dec2);
\draw	[arrow]		(dec2)	-- node[near start,anchor=west] {faux} (fail);
\draw	[arrow]		(dec2)	-- node[near start, anchor=south] {vrai} (reussi);

\end{tikzpicture}
\end{center}
\caption{Structure de validation de données $d$ par un test $t$. $Out$ vaut "$|Rangs\leq 50$ \&\& $Rangs \geq 950|$"  }
\end{figure}

%\node 	(source)		[process,below of=titre,yshift=1cm, xshift=0.5cm]	{Source d'entropie};
%\node 	(conver)		[process,below of=source,xshift=1cm]		{Convertisseur};
%\node 	(bz2) 		[process,right of=conver, xshift=5cm]	{BZ2};
%\node	(score)		[right of=bz2, xshift=2cm] {Score};
%
%\begin{pgfonlayer}{background}
%\node[punkt, fit=(titre)(source)(conver)(bz2)(score), fill=yellow!5] (groupclient) {};
%\end{pgfonlayer}
%
%\draw	[arrow] (source)		-- node[anchor=west] {144 21 139 0 0 15}		(conver);
%\draw	[arrow] (conver)		-- node[anchor=north] {"144,21,139,0,0,15"}		(bz2);
%\draw	[arrow] (bz2)		-- node[anchor=north] {21}		(score);


\subsubsubsection{Score de compression}
Les algorithmes de compressions sont habituellement bien adaptés pour supprimer les données redondantes des chaînes de caractère. Suivant un algorithme de compression choisi, le score de compression est la longueur de la donnée compressée obtenue. 

\paragraph{Calcul du score.\\}
Le score est calculé de la façon suivante :
\begin{enumerate}
\item Les sous ensembles de données sont encodés en chaîne de caractère séparés par une virgule
\item La chaîne de caractère est compressée suivant l'algorithme de compression de bzip2 \footnote{cf. \url{www.bzip.org}}
\item Le score retourné correspond à la longueur de la chaîne de caractère compressée
\end{enumerate}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node 	(titre) 		{\textbf{Score de compression}};
\node 	(source)		[process,below of=titre,yshift=1cm, xshift=0.5cm]	{Source d'entropie};
\node 	(conver)		[process,below of=source,xshift=1cm]		{Convertisseur};
\node 	(bz2) 		[process,right of=conver, xshift=5cm]	{BZ2};
\node	(score)		[right of=bz2, xshift=2cm] {Score};

\begin{pgfonlayer}{background}
\node[punkt, fit=(titre)(source)(conver)(bz2)(score), fill=yellow!5] (groupclient) {};
\end{pgfonlayer}

\draw	[arrow] (source)		-- node[anchor=west] {144 21 139 0 0 15}		(conver);
\draw	[arrow] (conver)		-- node[anchor=north] {"144,21,139,0,0,15"}		(bz2);
\draw	[arrow] (bz2)		-- node[anchor=north] {21}		(score);
\end{tikzpicture}
\end{center}
\caption{Calcul du score de compression}
\end{figure}

\subsubsubsection{Scores \textit{Over/Under Runs} (2)}
\paragraph{Définition.\\}
On définit le \textbf{\textit{run test}} comme la série des valeurs montantes ou la série des valeurs décroissantes. Le terme de \texttt{run} peut être expliqué comme la successions d'éléments de la même classe. Le nombre d'augmentations ou de réductions définit la longueur du test.  Dans un jeu de données aléatoire, la probabilité que la $(i+1)$ème valeur est plus grande ou plus petite que la $i$ème valeur doit suivre la loi binomiale.\\

Le \textit{run test} est défini tel que : 
\begin{itemize}
\item $H_0$ : la séquence a été produite de manière aléatoire
\item $H_1$ : la séquence n'a pas été produite de manière aléatoire
\item Test statistique : 
	$$ Z = \frac{R - \overline{R}}{s_R}$$
	où : 
	\begin{itemize}
	\item $R$ : le nombre de \textit{runs} observés
	\item $\overline{R}$, la moyenne (le nombre de runs attendus) telle que  :
	$$\overline{R}= \frac{2  N_+ N_-}{N}+1$$
	\item $s_R$ la variance (déviation standard) calculée telle que : 
	$$s_R^2 = \frac{2 N_+ N_-(2N_+ N_- -N)}{N^2(N-1)}  = \frac{(\overline{R}-1)(\overline{R}-2)}{N-1}$$
	\end{itemize}
\item Niveau significatif : $\alpha$
\item Zone critique : Le \textit{run test} rejette l'hypothèse nulle $H_0$  si $ |Z| > Z_{1-\alpha/2}$


\end{itemize}





\paragraph{Exemple de Run test.\\}
Soit la suite binaire $X=(x_1,x_2,...,x_n)$ sortie d'un générateur aléatoire. Pour tous les $i$ allant de $1$ à $n-1$. On stocke dans un vecteur de taille $n-1$ le signe de $x_{i+1}-x_i$. Le nombre de run consiste au nombre de changements de signe.

Si $X=111001111000110$, alors son vecteur associé sera $(++-+++++-++++-)$, soit 6 \textit{runs}. Dans le cas des suites binaires, il s'agit simplement de compter le nombre de changement d'éléments (ou classes), l'ensemble de données étant $\lbrace 0,1 \rbrace$. Si l'élément $i$ est équivalent au précédent, alors on passe au suivant, sinon on incrémente de un le nombre de \textit{runs}.\\

Ici on a donc : 
\begin{itemize}
\item $R = 6$
\item $\overline{R}= \frac{2*3*3}{15}+1 = 2.2 $
\item $s_R^2 = \frac{1.2*0.2}{14} = 0,017142857$
\item D'où $ Z = \frac{6 -2.2}{0,130930734} = 29.0229794$
\item On choisit un niveau $\alpha=0.05$
\item On cherche $Z_{1-\alpha/2}$. $\frac{1-\alpha}{2}=0.475$ soit suivant la courbe normale une valeur de  $Z_{1-\alpha/2}=1.96$. Ceci correspond à la valeur critique. La zone de rejet de $H_0$ est telle que $|Z| > 1.96$
\item Étant donné que $|Z| > 1.96$, on en conclu que les données ne sont pas aléatoires au risque de 5\%.\\

\end{itemize}


\paragraph{Calcul des scores \textit{Over/Under Runs}.\\}
Pour chaque sous-ensemble, on calcule la médiane des données. On identifie ensuite les données en 3 sous-ensembles :
\begin{itemize}
\item Soit elles sont égales à la médiane
\item Soit elles sont inférieures à la médiane
\item Soit elles sont supérieures à la médiane
\end{itemize}
Les sous ensembles inférieurs et supérieurs à la médiane sont susceptible d'avoir un \textit{run score} relativement faible, si les données sont suffisamment bien IID.\\

 
Les deux scores de \textit{over/under runs} sont calculés comme suit : 
\begin{enumerate}
\item On récupère la médiane de notre sous ensemble de données. Pour des données binaires, la médiane sera de 0.5
\item Pour chaque sous ensemble original et chaque sous ensemble permuté, un sous ensemble temporaire est construit comme suit. Pour chaque élément : 
	\begin{enumerate}
	\item Si l'élément est plus grand que la médiane, on ajoute \texttt{+1} au vecteur temporaire
 	\item Si l'élément est plus petit que la médiane, on ajoute \texttt{-1} au vecteur temporaire
	\item Si l'élément est égal à la médiane, on passe à l'élément suivant	
	\end{enumerate}
\item La plus grande  taille du \textit{run} sur les \texttt{+1} ou les \texttt{-1} est considéré comme le premier score 
\item La taille du \textit{run} sur les \texttt{+1} et les \texttt{-1} est considéré comme le second score.
\end{enumerate}

\paragraph{Exemple.\\}
Considérant l'ensemble de taille 7 ayant les données suivantes : $\lbrace 5,15,12,1,13,9,4\rbrace$.
\begin{enumerate}
\item  On récupère la médiane : $9$
\item  Création du vecteur temporaire : $5<9 \Rightarrow -1 ...$. Vecteur final : $\lbrace -1, +1,+1,-1,+1,-1 \rbrace$. On note que pour ce vecteur la valeur 9 a été omise.
\item Le \textit{run} le plus long pour le \texttt{+1} et le \texttt{-1} est de taille 2, (score 1)
\item Le \textit{run} global est de taille 5, (score 2)
\end{enumerate}

\subsubsubsection{Score excursion}
Le score d'excursion mesure la déviation en chaque point d'une somme d'éléments suivant leur moyenne.

\paragraph{Définition.\\}
 Étant donné les éléments $(s_0,s_1,...,s_i)$, et leur moyenne $\mu_i$,  \textbf{l'excursion} $Esc_i$ est définie telle que :
 $$ Esc_i= s_0+ s_1 + ... + s_i - i*\mu$$ 
Le score retourné est l'excursion maximale en valeur absolue du sous ensemble de données. \\

\paragraph{Calcul du score.\\}
Le score est ainsi calculé comme suit. $\mu$ est défini comme la moyenne des valeurs d'un ensemble donné.
\begin{enumerate}
\item Pour $j=1$ à $ \lfloor\frac{N}{10}\rfloor$ (taille des données du sous ensemble), on calcule $d_j=|Esc_j| = |\sum\limits_{i=0}^{j} s_i|$
\item $\text{Score} = \Max\limits_{j=0,j<=\lfloor\frac{N}{10}\rfloor} (d_j)$
\end{enumerate}

\paragraph{Exemples.\\}
Étant donné le sous ensemble suivant : $ \lbrace 2, 15, 4, 10, 9 \rbrace$. 
\begin{enumerate}
\item On calcule $\mu$, ici $\mu=8$
\item Calcul des $d_j$ :\\
$d_1=|2-8|=6$, $d_2=|2+15-2*8|$, $d_3=3$, $d_4=1$, $d_5=0$
\item Le score est donc de $6$\\
\end{enumerate}

\subsubsubsection{Scores Runs directionnel (3)}
Le principe du run test reste le même que celui évoqué précédement à l'exception suivante près:  lorsqu'il y a égalité entre deux éléments consécutifs, on le référence comme étant 0 dans le vecteur temporaire plutôt que de passer directement à l'élément suivant. 

\paragraph{Calcul des scores pour des données quelconques.\\}
Le score est calculé de la façon suivante : 
\begin{enumerate}
\item Le nombre total de runs (sans considérer le 0 comme un changement de "signe") (score 1)
\item La longueur du plus long run (les 0 sont également ignorés)  (score 2)
\item Le maximum entre le nombre de données \texttt{+1} et le nombre de données \texttt{-1} (score 3)\\

\end{enumerate}


\textbf{Exemple :} \\
Étant donné l'ensemble suivant : $\lbrace 2, 2, 2, 5, 7, 7, 9, 3, 1, 4, 4 \rbrace$. 
\begin{enumerate}
\item  On calcule son vecteur temporaire lié $ \lbrace 0, 0, +1, +1, 0, +1, -1, -1, +1, 0 \rbrace $
\item Nous comptons 3 séries de run : $(0,0,+1,+1,0,+1)$, $(-1,-1)$ et $(+1,0)$ (score 1)
\item Le run le plus long est de $4$ : $(+1,+1,0,+1)$ (score 2)
\item On compte 4 \texttt{+1} et 4 \texttt{-1}, le maximum des deux est donc de 4 (score 3).
\end{enumerate}


\paragraph{Données binaires.\\}
Dans le cadre des données binaires en sortie de source d'entropie, il convient de faire un pré-traitement sur les données : 
\begin{enumerate}
\item On convertit les bits en bytes.
\item On calcule le poids de hamming pour ces éléments : \\
Pour $i=0$ à  $\frac{\lfloor\frac{N}{10}\rfloor}{8} -1 $, on stocke dans $W_i$ son poids de Hamming, tel que $W_i=hamming\_weight(s_i,...,s_{i+7})$
\item On réitère l'opération des données quelconques à partir de ce vecteur $W_i$.
\end{enumerate}

\paragraph{Poids de Hamming.\\}
Le \textbf{poids de hamming} d'un sous ensemble $(s_i,...,s_{i+n})$ , donné par $hamming\_weight(s_i,...,s_{i+n})$ est défini comme le nombre de 1 de la suite $(s_i,...,s_{i+n})$.



\subsubsubsection{Score de covariance}
Le score de covariance permet de détecter la relation entre les valeurs numériques successives. En effet, toute relation linéaire entre des paires successives va affecter directement ce score. On pourra alors constater une différence entre la covariance calculée sur le sous ensemble de données originales et la covariances calculée sur le sous ensemble de données permutées. La covariance est calculée entre chaque paire consécutive du sous ensemble S tel que $s_i$ est apparié avec $s_{i+1}$.\\

\paragraph{Calcul du score.\\}
Le score est calculé comme suit : 
\begin{enumerate}
\item la variable $count$ est initialisée à 0.
\item $\mu$, moyenne des données de $s_0$ à $s_{\lfloor\frac{N}{10}\rfloor-1}$ est calculée.
\item Pour $i=1$ à $\lfloor\frac{N}{10}\rfloor$ on incrémente $count$ tel que :
$$count = count + (s_i - \mu)(s_{i-1} - \mu)$$
\item On obtient enfin le score : $Score = \lfloor \frac{count}{\lfloor\frac{N}{10}\rfloor-1} \rfloor$
\end{enumerate}

\paragraph{Exemple.\\}
Étant donné le sous-ensemble  : $\lbrace 15, 2 ,6 , 10; 12 \rbrace$ de 5 éléments :
\begin{enumerate}
\item $\mu = 9$
\item 	\begin{itemize}
		\item Pour $i=1$, $count =0 + (2-9)(15-9) = -42$
		\item Pour $i=2$, $count = -42 + (6-9)(2-9) = -21$
		\item Pour $i=3$, $count = -24$
		\item Pour $i=4$, $count = -21$
		\end{itemize}
\item $Score = \lfloor \frac{-21}{4} \rfloor = -5$
\end{enumerate}

\subsubsubsection{Score de collision (3)}
Une façon naturelle de tester l'entropie d'un générateur est de mesurer le nombre d'essais nécessaires pour obtenir une valeur identique à la première, en d'autres termes, le nombre d'essais nécessaires pour obtenir une collision. Ainsi,  notre score de collision va mesurer le nombre d'essais successifs jusqu'à ce qu'un élément identique soit trouvé.\\


Dans le cas des données binaires, un sous ensemble de données binaires est converti en séquence de 8bits avant d'être testé. \\

\paragraph{Calcul des scores.\\}
Les 3 scores de collisions sont calculés comme suit : 
\begin{enumerate}
\item $Counts$  est une liste d'échantillons nécessaires pour trouver une collision. La liste est vide à l'initialisation.
\item $pos=0$
\item Tant que $pos < \lfloor\frac{N}{10}\rfloor$
	\begin{enumerate}
	\item Trouver le plus petit $j$ tel que $s_{pos} ... s_{pos+j}$
		\begin{enumerate}
		\item Si aucun $j$ de ce type n'existe, on sort de la boucle tant que
		\end{enumerate}
	\item Ajouter $j$ à la liste $Counts$
	\item $pos = pos + j + 1$
	\end{enumerate}
\item On retourne les scores suivants : 
	\begin{enumerate}
	\item La valeur minimale de la liste $Counts$ (score 1)
	\item La moyenne de la liste $Counts$ (score 2)
	\item La valeur maximale de la liste $Counts$ (score 3)
	\end{enumerate}
\end{enumerate}

\paragraph{Exemple.\\}
Considérant les données : $ \lbrace 2, 1, 1, 2, 0, 1, 0, 1, 1, 2 \rbrace$ de taille $10$.
\begin{enumerate}
\item On exécute le contenu de la boucle tant que : 
	\begin{enumerate}
	\item Considérant $2$ comme la $0$e valeur, la première collision apparaît à $j=2$, pour la valeur \texttt{1}.
	\item On passe à une analyse sur le reste de l'ensemble initial non analysé : $ \lbrace 2, 0, 1, 0, 1, 1, 2 \rbrace$. La première collision de ce sous-ensemble apparaît en $j=3$, pour la valeur \texttt{0}.
	\item On travaille à présent sur l'ensemble  $ \lbrace  1, 1, 2 \rbrace$. La première collision apparaît en $j=1$
	\item Enfin, on ne trouve aucune collision sur l'ensemble $\lbrace 2 \rbrace $
	\end{enumerate}
\item On retourne les scores : 
	\begin{enumerate}
	\item $min(Counts) = 1$ (score 1)
	\item $\mu_{Counts} = 2$ (score 2)
	\item $Max(Counts) = 3$ (score 3)
	\end{enumerate}

\end{enumerate}

\subsubsection{Test statistique spécifique : \chidpdf}
Dès lors que source d'entropie est considérée comme IID, alors la distribution de ces valeurs peut être considérée comme une distribution indépendante, une distribution multinomiale.

\paragraph{Définition.\\}
La \textbf{loi multinomiale} est une généralisation de la loi binomiale. On considère $m$ résultats possibles (2 pour la loi binomiale). Soit $N_i$ pour $i \in \lbrace1,...,m\rbrace$ la variable aléatoire multinomiale ayant une probabilité $p_i$, telle que :
\begin{center}
$ \sum \limits_{i=1}^{m} N_i = 1$ et  $\sum \limits_{i=1}^{m} p_i = 1$ 
\end{center}
La densité de probabilité de cette loi s'écrit : 
$$ \mathbb{P}(N_1=n_1, ..., N_m = n_m) = \frac{n!}{n_1! ... n_m!}p_1^{n_1}...p_m^{n_m}$$
Pour respectivement les espérances et variances suivantes :
\begin{center}
$ \mathbb{E}[N_i]=np_i$ et $\mathbb{V}[N_i]=np_i(1-p_i)$
\end{center}

\paragraph{Approximation.\\}
Si les variables sont indépendantes, $\sum \limits_{i=1}^m \frac{(N_i - np_i)^2}{np_i(1-p_i)}$ suit une loi du \chidpdf à $m$ degrés de libertés. Ainsi, le test du \chidpdf peut ici être utilisé pour tester si des données suivent une distribution multinomiale.\\


Plus généralement, le test peut être utilisé pour vérifier si des données suivent une distribution particulière, pourvu que celles-ci ne soient pas de trop grande taille. Deux types de tests sont proposés sur la source d'entropie : 
\begin{itemize}
\item Le test d'indépendance entre des données successives obtenues (tests différents pour des données binaires et non binaires)
\item Le test d'ajustement sur les 10 sous-ensembles de données, qui permet de vérifier si le modèle adopté pour les données est satisfaisant, ie. dans quelle mesure les résidus sont dus au hasard (tests différents pour des données binaires et non binaires). 

Nous ne détaillerons pas dans ce rapport ces tests respectifs. Ils sont toutefois décrits dans le document du NIST SP800-90b.

\end{itemize}



\subsection{Déterminer l'entropie minimale des sources IID}
On souhaite à présent estimer l'entropie fournie par une source IID (données indépendantes et identiquement distribuées). 
Ce test est basé sur le nombre d'observations d'un échantillon le plus courant de la source de bruit ($pmax$). Le but est de calculer la borne minimale d'entropie de la source.\\

\paragraph{Calcul de l'entropie minimale.\\}
Étant donné N échantillons $\lbrace x_1, ... x_n \rbrace$
\begin{enumerate}
\item Trouver la valeur la plus souvent rencontrée dans le jeu de données
\item Compter le nombre d’occurrences de cette valeur, stocké dans $C_{MAX}$
\item Calculer  $pmax= \frac{C_{MAX}}{N}$
\item Calculer $C_{BOUND} = C_{MAX} + 2.3 \sqrt{N*pmax(1-pmax)} $
\item Calculer $ H = -log_2(\frac{C_{BOUND}}{N})$
\item Calculer le nombre d'éléments dans l'échantillon, que l'on stocke dans W. 
\item $min(W,H)$ est l'entropie minimale
\end{enumerate}


\paragraph{Exemple.\\}
Considérant le jeu de données  $\lbrace 0,1,1,2,0,1,2,2,0,1,0,1,1,0,2,2,1,0,2,1 \rbrace$ de 20 données :
\begin{itemize}
\item La valeur la plus courant du jeu de données est \texttt{1} (On compte 6 \texttt{0}, 8 \texttt{1} et 6 \texttt{2})
\item $C_{MAX} = 8$
\item $pmax = \frac{8}{20} = 0.4$
\item $ C_{BOUND} = 8 + 2.3 \sqrt{20*0.4*0.6} = 13.04$
\item $ H = -log_2(\frac{13.04}{20}) = 0.186$
\item $ W = 3$
\item Entropie minimale calculée : $ min(3,0.186) = 0.186$
\end{itemize}

